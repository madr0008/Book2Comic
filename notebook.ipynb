{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtSTxptqDMtP"
      },
      "source": [
        "# Book2Comic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slSPgVw0DSCe"
      },
      "source": [
        "Example notebook for checking all available features for the tool.\n",
        "\n",
        "Developed by Miguel Ángel Dávila Romero and Tomás Alcántara Carrasco."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzeQ67mDduU"
      },
      "source": [
        "## Environment setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlAnEoQwDpgF"
      },
      "source": [
        "Before running everything, make sure you are connected to a **GPU environment**.\n",
        "\n",
        "After that, execute the following cells for installing requirements and importing libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1-TGJfeEeqY"
      },
      "source": [
        "### Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ouj-WvHEdt1",
        "outputId": "90e23c07-80f5-4838-be8d-d7a920c7338e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: booknlp in /usr/local/lib/python3.10/dist-packages (1.0.7.1)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from booknlp) (2.2.1+cu121)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.10/dist-packages (from booknlp) (3.7.4)\n",
            "Requirement already satisfied: transformers<=4.30.0,>=4.11.3 in /usr/local/lib/python3.10/dist-packages (from booknlp) (4.30.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3->booknlp) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->booknlp) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->booknlp) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (0.4.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->booknlp) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->booknlp) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->booknlp) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->booknlp) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->booknlp) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy>=3->booknlp) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3->booknlp) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3->booknlp) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->booknlp) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->booknlp) (1.1.1)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "! pip install booknlp\n",
        "! python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V75a6_9EEh52"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR8qNyPb0seo",
        "outputId": "8a8d79f5-ec89-4c27-cd95-f97720f8a063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device cuda\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "import IPython.display as display\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageOps, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import torch.optim as optim\n",
        "from booknlp.booknlp import BookNLP\n",
        "import base64\n",
        "import json\n",
        "import spacy\n",
        "import requests\n",
        "import io\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7-k9wliEx-6"
      },
      "source": [
        "## Utils for execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5agDg1IE2tA"
      },
      "source": [
        "### Face detection utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj0C56u21mlu"
      },
      "outputs": [],
      "source": [
        "# External Libraries\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "###########################################################\n",
        "# COMMON PARAMETERS\n",
        "###########################################################\n",
        "\"\"\"\n",
        "\n",
        "# Device Parameters\n",
        "run_gpu             = False\n",
        "device              = \"cuda\" if run_gpu else \"cpu\"\n",
        "\n",
        "# Train Parameters\n",
        "weight_decay        = 0.0005\n",
        "\n",
        "\"\"\"\n",
        "###########################################################\n",
        "# DETECTOR PARAMETERS\n",
        "###########################################################\n",
        "\"\"\"\n",
        "# Training Parameters\n",
        "rf_bs               = 20\n",
        "\n",
        "# Loss Calculation Metrics\n",
        "pos_iou             = 0.5\n",
        "neg_iou             = 0.3\n",
        "ohem_ratio          = 3\n",
        "lambda1             = 2\n",
        "variances           = [0.2, 0.1]\n",
        "\n",
        "\n",
        "class Backbone(torch.nn.Module):\n",
        "    def __init__(self, backbone=\"resnet50\"):\n",
        "        super(Backbone, self).__init__()\n",
        "\n",
        "        if backbone == \"resnet50\" or backbone == \"resnet152\":\n",
        "            if backbone == \"resnet50\":\n",
        "                backbone = models.resnet50(pretrained=True)\n",
        "            elif backbone == \"resnet152\":\n",
        "                backbone = models.resnet152(pretrained=True)\n",
        "            self.in_sizes = [256, 512, 1024, 2048]\n",
        "            self.init_layer = nn.Sequential(\n",
        "                backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool\n",
        "            )\n",
        "            self.layer1 = backbone.layer1\n",
        "            self.layer2 = backbone.layer2\n",
        "            self.layer3 = backbone.layer3\n",
        "            self.layer4 = backbone.layer4\n",
        "\n",
        "        elif backbone == \"mobilenetv2\":\n",
        "            backbone = models.mobilenet_v2(pretrained=True)\n",
        "            self.in_sizes = [24, 32, 96, 160]\n",
        "            self.init_layer = backbone.features[0]\n",
        "            self.layer1 = backbone.features[1:4]\n",
        "            self.layer2 = backbone.features[4:7]\n",
        "            self.layer3 = backbone.features[7:14]\n",
        "            self.layer4 = backbone.features[14:19] # may be 18 also\n",
        "\n",
        "    def forward(self, x):\n",
        "        c2 = self.layer1(self.init_layer(x))\n",
        "        c3 = self.layer2(c2)\n",
        "        c4 = self.layer3(c3)\n",
        "        c5 = self.layer4(c4)\n",
        "        return [c2, c3, c4, c5]\n",
        "\n",
        "class ConvBnRelu(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        padding=0,\n",
        "        stride=1,\n",
        "        dilation=1,\n",
        "        groups=1,\n",
        "        bias=False,\n",
        "        momentum=0.1,\n",
        "        eps=1e-5,\n",
        "        leaky=0,\n",
        "        ):\n",
        "        super(ConvBnRelu, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size,\n",
        "            stride=stride, dilation=dilation,padding=padding,\n",
        "            groups=groups, bias=bias\n",
        "            )\n",
        "        self.bn = BatchNorm2d(out_channels,eps=eps,momentum=momentum)\n",
        "\n",
        "        if leaky == -1:\n",
        "            self.activ = None\n",
        "        elif leaky == 0:\n",
        "            self.activ = nn.ReLU()\n",
        "        else:\n",
        "            self.activ = nn.LeakyReLU(negative_slope=leaky)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_val = self.bn(self.conv(x))\n",
        "        if self.activ != None:\n",
        "            return self.activ(x_val)\n",
        "        return x_val\n",
        "\n",
        "class ConvBnRelu(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        padding=0,\n",
        "        stride=1,\n",
        "        dilation=1,\n",
        "        groups=1,\n",
        "        bias=False,\n",
        "        momentum=0.1,\n",
        "        eps=1e-5,\n",
        "        leaky=0,\n",
        "        ):\n",
        "        super(ConvBnRelu, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size,\n",
        "            stride=stride, dilation=dilation,padding=padding,\n",
        "            groups=groups, bias=bias\n",
        "            )\n",
        "        self.bn = BatchNorm2d(out_channels,eps=eps,momentum=momentum)\n",
        "\n",
        "        if leaky == -1:\n",
        "            self.activ = None\n",
        "        elif leaky == 0:\n",
        "            self.activ = nn.ReLU()\n",
        "        else:\n",
        "            self.activ = nn.LeakyReLU(negative_slope=leaky)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_val = self.bn(self.conv(x))\n",
        "        if self.activ != None:\n",
        "            return self.activ(x_val)\n",
        "        return x_val\n",
        "\n",
        "class SSH(torch.nn.Module):\n",
        "    def __init__(self, in_size=256, out_size=256):\n",
        "        super(SSH, self).__init__()\n",
        "        out_size4 = in_size//4; out_size2 = in_size//2\n",
        "        self.conv128 = ConvBnRelu(in_size, out_size2, 3, bias=False, padding=1, leaky=-1)\n",
        "        self.conv64_1_1 = ConvBnRelu(in_size, out_size4, 3, bias=False, padding=1)\n",
        "        self.conv64_1_2 = ConvBnRelu(out_size4, out_size4, 3, bias=False, padding=1, leaky=-1)\n",
        "        self.conv64_2_1 = ConvBnRelu(out_size4, out_size4, 3, bias=False, padding=1)\n",
        "        self.conv64_2_2 = ConvBnRelu(out_size4, out_size4, 3, bias=False, padding=1, leaky=-1)\n",
        "        self.activ = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.conv128(x)\n",
        "        o2_1 = self.conv64_1_1(x)\n",
        "        o2_2 = self.conv64_1_2(o2_1)\n",
        "        o3_1 = self.conv64_2_1(o2_1)\n",
        "        o3_2 = self.conv64_2_2(o3_1)\n",
        "        return self.activ(torch.cat([o1, o2_2, o3_2], dim=1))\n",
        "\n",
        "class ContextModule(torch.nn.Module):\n",
        "    def __init__(self, in_size=256, out_size=256):\n",
        "        super(ContextModule, self).__init__()\n",
        "        self.ssh_list = nn.ModuleList()\n",
        "        for i in range(5):\n",
        "            self.ssh_list.append(SSH(in_size=in_size, out_size=out_size))\n",
        "\n",
        "    def forward(self, xs):\n",
        "        outs = []\n",
        "        for i in range(len(xs)):\n",
        "            outs.append(self.ssh_list[i](xs[i]))\n",
        "        return outs\n",
        "\n",
        "class FeaturePyramid(torch.nn.Module):\n",
        "    def __init__(self, in_sizes=[256, 512, 1024, 2048], out_size=256):\n",
        "        super(FeaturePyramid, self).__init__()\n",
        "\n",
        "        self.lateral_ins = nn.ModuleList()\n",
        "        # getting layers for lateral connections\n",
        "        for ins in in_sizes:\n",
        "            self.lateral_ins.append(ConvBnRelu(ins, out_size, 1, bias=False))\n",
        "\n",
        "        self.lateral_ins.append(\n",
        "            ConvBnRelu(in_sizes[-1], out_size, 3, stride=2, padding=1, bias=False)\n",
        "        )\n",
        "        self.extra = True\n",
        "        self.lateral_outs = nn.ModuleList()\n",
        "        for _ in range(len(self.lateral_ins)-1):\n",
        "            self.lateral_outs.append(\n",
        "                ConvBnRelu(out_size, out_size, 3, padding=1, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, xs):\n",
        "        outs = []\n",
        "        outs.append(self.lateral_ins[-1](xs[-1])) # P6\n",
        "\n",
        "        inter_outs = []\n",
        "        for idx in range(4):\n",
        "            inter_outs.append(self.lateral_ins[idx](xs[idx]))\n",
        "        outs.append(inter_outs[-1]) # P5\n",
        "\n",
        "        for idx in range(3, 0, -1):\n",
        "            conn = F.interpolate(\n",
        "                inter_outs[idx],\n",
        "                size=[inter_outs[idx-1].size(2), inter_outs[idx-1].size(3)],\n",
        "                mode=\"nearest\"\n",
        "            )\n",
        "            outs.append(self.lateral_outs[idx-1](conn + inter_outs[idx-1])) # P4, P3, P2\n",
        "\n",
        "        outs.reverse()\n",
        "        return outs\n",
        "\n",
        "class HeadGetter(torch.nn.Module):\n",
        "    def __init__(self, input_dims, task_len, lateral_conn=5, num_anchors=3):\n",
        "        super(HeadGetter, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.task_len = task_len\n",
        "        for _ in range(lateral_conn):\n",
        "            self.layers.append(\n",
        "                nn.Conv2d(input_dims, num_anchors*task_len, 1, bias=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, xs):\n",
        "        proposals = []\n",
        "        T = self.task_len\n",
        "        for i, x in enumerate(xs):\n",
        "            proposal = self.layers[i](x)\n",
        "            N, C, H, W = proposal.size()\n",
        "            A = int(W*H*(C/T))\n",
        "            proposal = proposal.permute(0,2,3,1).contiguous()\n",
        "            proposal = proposal.view(proposal.shape[0], -1, T)\n",
        "            proposals.append(proposal)\n",
        "        return torch.cat(proposals, dim=1)\n",
        "\n",
        "def read_image(img_path, boxes, augment=True, resize_len=[640, 640]):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    box = np.array(boxes).copy() if boxes is not None else None\n",
        "\n",
        "    if augment:\n",
        "        img, box = crop(img, box)\n",
        "        img = distort_color(img)\n",
        "        img, box = horizontal_flip(img, box)\n",
        "        img, box = resize(img, box, resize_len)\n",
        "\n",
        "    elif resize_len[0] > 0 and resize_len[0] == resize_len[1]:\n",
        "        img = squaritize(img)\n",
        "        img, box = resize(img, box, resize_len)\n",
        "    else:\n",
        "        img, box = resize(img, box, resize_len)\n",
        "\n",
        "    img = normalize(transforms.ToTensor()(img))\n",
        "    box = torch.Tensor(box) if box is not None else None\n",
        "    if run_gpu:\n",
        "        img = img.cuda(); box = box.cuda() if box is not None else None\n",
        "\n",
        "    if box is not None:\n",
        "        return img, box\n",
        "    else:\n",
        "        return img\n",
        "\n",
        "\n",
        "def normalize(img, means=[0.485, 0.456, 0.406], stds=[0.229, 0.224, 0.225]):\n",
        "    return TF.normalize(img, mean=means, std=stds)\n",
        "\n",
        "\"\"\"\n",
        "mode -> 0 : add right and bottom size\n",
        "mode -> 1 : add left and upper side\n",
        "mode -> 2 : center the image\n",
        "\"\"\"\n",
        "def squaritize(img, mode=0):\n",
        "    W, H = img.size\n",
        "    if W == H:\n",
        "        return img\n",
        "    max_len = max(W, H)\n",
        "    delta_w = max_len - W; delta_h = max_len - H\n",
        "    if mode == 0:\n",
        "        padding = (0, 0, delta_w, delta_h)\n",
        "    elif mode == 1:\n",
        "        padding = (delta_w, delta_h, 0, 0)\n",
        "    else:\n",
        "        padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
        "    return ImageOps.expand(img, padding)\n",
        "\n",
        "\n",
        "def distort_color(img):\n",
        "    if np.random.rand() > 0.5:\n",
        "        br_strength = np.random.randint(4, 21) / 10\n",
        "        img = TF.adjust_brightness(img, br_strength) # 0.4 - 2.0 range\n",
        "    if np.random.rand() > 0.5:\n",
        "        con_strength = np.random.randint(4, 31) / 10\n",
        "        img = TF.adjust_contrast(img, con_strength) # 0.4 - 3.0 range\n",
        "    if np.random.rand() > 0.5:\n",
        "        hue_strength = np.random.randint(-5, 5) / 10\n",
        "        img = TF.adjust_hue(img, hue_strength) # -0.4 - 0.4 range\n",
        "    if np.random.rand() > 0.5:\n",
        "        sat_strength = np.random.randint(-1, 20) / 10\n",
        "        img = TF.adjust_saturation(img, sat_strength) # 0.0 - 2.0 range\n",
        "    return img\n",
        "\n",
        "\n",
        "def horizontal_flip(img, box):\n",
        "    if np.random.rand() > 0.5:\n",
        "        W, H = img.size\n",
        "        img = TF.hflip(img)\n",
        "        if box is not None:\n",
        "            box[:,0:4:2] = W - box[:,0:4:2]\n",
        "            box[np.where(box > W)] = -1\n",
        "            temp = box[:,0].copy()\n",
        "            box[:,0] = box[:,2]\n",
        "            box[:,2] = temp\n",
        "    return img, box\n",
        "\n",
        "\n",
        "def resize(img, box, resize_len):\n",
        "    W, H = img.size\n",
        "    resize_len[0] = W if resize_len[0] < 0 else resize_len[0]\n",
        "    resize_len[1] = H if resize_len[1] < 0 else resize_len[1]\n",
        "    w_ratio = resize_len[0]/W; h_ratio = resize_len[1]/H\n",
        "\n",
        "    img = TF.resize(img, (resize_len[1], resize_len[0]))\n",
        "    if box is not None:\n",
        "        box[:,0:4:2] *= w_ratio\n",
        "        box[:,1:4:2] *= h_ratio\n",
        "    return img, box\n",
        "\n",
        "\n",
        "def crop(img, box):\n",
        "    W, H = img.size\n",
        "    min_len = min(W, H)\n",
        "    crop_ratios = [0.3, 0.45, 0.6, 0.8, 1.0]\n",
        "\n",
        "    while True: # at least center of one face will be in cropped image\n",
        "        crop_ratio = np.random.choice(crop_ratios)\n",
        "        side_len = min_len * crop_ratio - 1\n",
        "        w_start = np.random.randint(0, max(1, W - side_len + 1))\n",
        "        h_start = np.random.randint(0, max(1, H - side_len + 1))\n",
        "\n",
        "        centers = box[:,2:4] - box[:,0:2]\n",
        "        in_bound = (w_start <= centers[:,0])*(centers[:,0] <= w_start + side_len)\n",
        "        in_bound *= (h_start <= centers[:,1])*(centers[:,1] <= h_start + side_len)\n",
        "        in_bound = np.where(in_bound == True)[0].flatten()\n",
        "\n",
        "        if len(in_bound) > 0:\n",
        "            break\n",
        "\n",
        "    box = box[in_bound, :]\n",
        "\n",
        "    img = TF.crop(img, h_start, w_start, side_len, side_len)\n",
        "    if box is not None:\n",
        "        box[:,0:4:2] -= w_start\n",
        "        box[:,1:4:2] -= h_start\n",
        "        box[:,0:4] = np.minimum(side_len, np.maximum(0, box[:,0:4]))\n",
        "        corr_x = np.where(box[:,2]-box[:,0] > 0)\n",
        "        corr_y = np.where(box[:,3]-box[:,1] > 0)\n",
        "        visible_faces = np.intersect1d(corr_x, corr_y)\n",
        "        box = box[visible_faces,:]\n",
        "    return img, box\n",
        "\n",
        "def get_PIL_image(img_tensor):\n",
        "    img = img_tensor.to(\"cpu\")\n",
        "    means = torch.Tensor([[[0.485]], [[0.456]], [[0.406]]])\n",
        "    stds = torch.Tensor([[[0.229]], [[0.224]], [[0.225]]])\n",
        "    return transforms.ToPILImage()(img * stds + means)\n",
        "\n",
        "class ICF_Data:\n",
        "\n",
        "    def __init__(self, icf_path, labels_path, batch_size=1, augment=True, img_sizes=[640, 640]):\n",
        "\n",
        "        self.imgs_path = []\n",
        "        self.boxes  = {}\n",
        "        self.augment = augment\n",
        "        self.img_sizes = img_sizes\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        f = open(labels_path,'r')\n",
        "        lines = f.readlines()\n",
        "        f.close()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.rstrip().split(',')\n",
        "            labels = [float(x) for x in line[1:]]\n",
        "            person_annot = np.zeros(4)\n",
        "            person_annot[0:4] = labels[0:4]\n",
        "            if icf_path + line[0] not in self.boxes:\n",
        "                self.boxes[icf_path + line[0]] = []\n",
        "            self.boxes[icf_path + line[0]].append(person_annot)\n",
        "\n",
        "        for k in self.boxes.keys():\n",
        "            self.boxes[k] = np.array(self.boxes[k])\n",
        "\n",
        "        self.imgs_path = [*self.boxes.keys()]\n",
        "\n",
        "        if self.augment:\n",
        "            self.state = np.random.permutation(len(self.imgs_path))\n",
        "        else:\n",
        "            self.state = np.arange(len(self.imgs_path))\n",
        "\n",
        "\n",
        "    def forward(self, restart=False):\n",
        "        if restart:\n",
        "            if self.augment:\n",
        "                self.state = np.random.permutation(len(self.imgs_path))\n",
        "            else:\n",
        "                self.state = np.arange(len(self.imgs_path))\n",
        "\n",
        "        if self.state is None or len(self.state) < self.batch_size:\n",
        "            return None, None\n",
        "        else:\n",
        "            indices = self.state[0:self.batch_size].copy()\n",
        "            self.state = None if len(self.state)  == self.batch_size else self.state[self.batch_size:]\n",
        "\n",
        "            if self.batch_size > 1 and self.img_sizes[0] > 0:\n",
        "                x = torch.zeros(self.batch_size, 3, self.img_sizes[1], self.img_sizes[0]).to(device)\n",
        "\n",
        "            y = []\n",
        "            for i, idx in enumerate(indices):\n",
        "                img_path = self.imgs_path[idx]\n",
        "                boxes = self.boxes[img_path]\n",
        "                img, box = read_image(img_path, boxes, self.augment, self.img_sizes)\n",
        "                y.append(box)\n",
        "                if self.batch_size == 1:\n",
        "                    return img.unsqueeze(0), y\n",
        "                else:\n",
        "                    x[i,:,:,:] = img\n",
        "\n",
        "            return x, y\n",
        "\n",
        "class Mixed_Data:\n",
        "\n",
        "    def __init__(self, wf_path, wf_labels_path, icf_path, icf_labels_path, batch_size=1, augment=True, img_sizes=[640, 640]):\n",
        "\n",
        "        self.augment = augment\n",
        "        self.img_sizes = img_sizes\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.boxes = {}; self.imgs_path = []\n",
        "        icf_paths, icf_boxes = self.get_icf_data(icf_path, icf_labels_path)\n",
        "        self.boxes.update(icf_boxes);  self.imgs_path.extend(icf_paths)\n",
        "        wf_paths, wf_boxes = self.get_wf_data(wf_path, wf_labels_path)\n",
        "        self.boxes.update(wf_boxes); self.imgs_path.extend(wf_paths)\n",
        "\n",
        "        if self.augment:\n",
        "            self.state = np.random.permutation(len(self.imgs_path))\n",
        "        else:\n",
        "            self.state = np.arange(len(self.imgs_path))\n",
        "\n",
        "\n",
        "    def get_wf_data(self, wf_path, wf_labels_path):\n",
        "        f = open(wf_labels_path,'r')\n",
        "        lines = f.readlines()\n",
        "        f.close()\n",
        "\n",
        "        boxes = {}; imgs_path = []\n",
        "        img_boxes = []; last_path = None\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.rstrip()\n",
        "            if line.startswith('#'):\n",
        "                if last_path is not None:\n",
        "                    boxes[last_path] = np.array(img_boxes)\n",
        "                    img_boxes = []\n",
        "                path = line[2:]\n",
        "                path = wf_path + 'images/' + path\n",
        "                last_path = path\n",
        "                imgs_path.append(path)\n",
        "            else:\n",
        "                line = line.split(' ')\n",
        "                labels = [float(x) for x in line]\n",
        "                person_annot = np.zeros(4)\n",
        "                person_annot[0:4] = labels[0:4]\n",
        "                person_annot[2:4] += person_annot[0:2]\n",
        "                img_boxes.append(person_annot)\n",
        "\n",
        "        boxes[last_path] = np.array(img_boxes)\n",
        "        return imgs_path, boxes\n",
        "\n",
        "    def get_icf_data(self, icf_path, icf_labels_path):\n",
        "        f = open(icf_labels_path,'r')\n",
        "        lines = f.readlines()\n",
        "        f.close()\n",
        "        boxes = {}\n",
        "        for line in lines:\n",
        "            line = line.rstrip().split(',')\n",
        "            person_annot = [float(x) for x in line[1:5]]\n",
        "            if icf_path + line[0] not in self.boxes:\n",
        "                boxes[icf_path + line[0]] = []\n",
        "            boxes[icf_path + line[0]].append(person_annot)\n",
        "\n",
        "        imgs_path = [*boxes.keys()]\n",
        "        return imgs_path, boxes\n",
        "\n",
        "\n",
        "    def forward(self, restart=False):\n",
        "        if restart:\n",
        "            if self.augment:\n",
        "                self.state = np.random.permutation(len(self.imgs_path))\n",
        "            else:\n",
        "                self.state = np.arange(len(self.imgs_path))\n",
        "\n",
        "        if self.state is None or len(self.state) < self.batch_size:\n",
        "            return None, None\n",
        "        else:\n",
        "            indices = self.state[0:self.batch_size].copy()\n",
        "            self.state = None if len(self.state)  == self.batch_size else self.state[self.batch_size:]\n",
        "\n",
        "            if self.batch_size > 1 and self.img_sizes[0] > 0:\n",
        "                x = torch.zeros(self.batch_size, 3, self.img_sizes[1], self.img_sizes[0]).to(device)\n",
        "\n",
        "            y = []\n",
        "            for i, idx in enumerate(indices):\n",
        "                img_path = self.imgs_path[idx]\n",
        "                boxes = self.boxes[img_path]\n",
        "                img, box = read_image(img_path, boxes, self.augment, self.img_sizes)\n",
        "                y.append(box)\n",
        "                if self.batch_size == 1:\n",
        "                    return img.unsqueeze(0), y\n",
        "                else:\n",
        "                    x[i,:,:,:] = img\n",
        "\n",
        "            return x, y\n",
        "\n",
        "class WF_Data:\n",
        "\n",
        "    def __init__(self, wf_path, labels_path, batch_size=1, augment=True, img_sizes=[640, 640]):\n",
        "\n",
        "        self.imgs_path = []\n",
        "        self.boxes  = {}\n",
        "        self.augment = augment\n",
        "        self.img_sizes = img_sizes\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        f = open(labels_path,'r')\n",
        "        lines = f.readlines()\n",
        "        f.close()\n",
        "\n",
        "        img_boxes = []; last_path = None\n",
        "        for line in lines:\n",
        "            line = line.rstrip()\n",
        "            if line.startswith('#'):\n",
        "                if last_path is not None:\n",
        "                    self.boxes[last_path] = np.array(img_boxes)\n",
        "                    img_boxes = []\n",
        "                path = line[2:]\n",
        "                path = wf_path + 'images/' + path\n",
        "                last_path = path\n",
        "                self.imgs_path.append(path)\n",
        "            else:\n",
        "                line = line.split(' ')\n",
        "                labels = [float(x) for x in line]\n",
        "                person_annot = np.zeros(4)\n",
        "                person_annot[0:4] = labels[0:4]\n",
        "                person_annot[2:4] += person_annot[0:2]\n",
        "                img_boxes.append(person_annot)\n",
        "\n",
        "        self.boxes[last_path] = np.array(img_boxes)\n",
        "\n",
        "        if self.augment:\n",
        "            self.state = np.random.permutation(len(self.imgs_path))\n",
        "        else:\n",
        "            self.state = np.arange(len(self.imgs_path))\n",
        "\n",
        "\n",
        "    def forward(self, restart=False):\n",
        "        if restart:\n",
        "            if self.augment:\n",
        "                self.state = np.random.permutation(len(self.imgs_path))\n",
        "            else:\n",
        "                self.state = np.arange(len(self.imgs_path))\n",
        "\n",
        "        if self.state is None or len(self.state) < self.batch_size:\n",
        "            return None, None\n",
        "        else:\n",
        "            indices = self.state[0:self.batch_size].copy()\n",
        "            self.state = None if len(self.state)  == self.batch_size else self.state[self.batch_size:]\n",
        "\n",
        "            if self.batch_size > 1 and self.img_sizes[0] > 0:\n",
        "                x = torch.zeros(self.batch_size, 3, self.img_sizes[1], self.img_sizes[0]).to(device)\n",
        "\n",
        "            y = []\n",
        "            for i, idx in enumerate(indices):\n",
        "                img_path = self.imgs_path[idx]\n",
        "                boxes = self.boxes[img_path]\n",
        "                img, box = read_image(img_path, boxes, self.augment, self.img_sizes)\n",
        "                y.append(box)\n",
        "                if self.batch_size == 1:\n",
        "                    return img.unsqueeze(0), y\n",
        "                else:\n",
        "                    x[i,:,:,:] = img\n",
        "\n",
        "            return x, y\n",
        "\n",
        "def encode_gt_and_get_indices(gt, priors, losses, pos_thold, neg_thold):\n",
        "\n",
        "    # getting positive anchor box indices\n",
        "    iou_vals = iou(gt[:,0:4], _to_min_max_form(priors))\n",
        "    pos_pairs = torch.where(iou_vals >= pos_thold)\n",
        "    prior_idx = pos_pairs[1]; gt_idx = pos_pairs[0]\n",
        "\n",
        "    num_poses = len(prior_idx)\n",
        "    if num_poses == 0:\n",
        "        return None, None, None\n",
        "\n",
        "    pos_gt = torch.zeros(num_poses, 15)\n",
        "    pos_gt = gt[gt_idx, :]\n",
        "\n",
        "    # getting negative box indices with the most loss values\n",
        "    max_prior_vals, max_prior_idx = iou_vals.max(0, keepdim=True)\n",
        "    neg_indices = torch.where(max_prior_vals <= neg_thold)[1]\n",
        "    neg_cnt = ohem_ratio * num_poses\n",
        "    neg_indices = neg_indices[torch.sort(losses[neg_indices]).indices[0:neg_cnt]]\n",
        "\n",
        "    # filtering w.r.t. the selected positive indices\n",
        "    pos_gt[:,0:4] = _to_center_length_form(pos_gt[:,0:4])\n",
        "    selected_priors = priors[prior_idx,:]\n",
        "\n",
        "    # box conversion to the target format\n",
        "    pos_gt[:,0:2] = (pos_gt[:,0:2] - selected_priors[:,0:2]) / (variances[1] * selected_priors[:,2:4])\n",
        "    pos_gt[:,2:4] = torch.log(pos_gt[:,2:4]/selected_priors[:,2:4]) / variances[0]\n",
        "\n",
        "    return pos_gt, prior_idx, neg_indices\n",
        "\n",
        "def nms(scores, points, thold):\n",
        "    order = torch.argsort(scores, descending=True)\n",
        "    keep = []\n",
        "    for i in order:\n",
        "        if keep == []:\n",
        "            keep.append(i.cpu().data.item())\n",
        "        else:\n",
        "            iou_vals = iou(points[i:i+1,:], points[keep,:])\n",
        "            vals = iou_vals.max(1, keepdim=True).values[0]\n",
        "            if vals[0] <= thold:\n",
        "                keep.append(i.cpu().data.item())\n",
        "    return np.array(keep)\n",
        "\n",
        "def _get_priorboxes(num_anchors, anchor_info, img_size):\n",
        "    feature_maps = [(ceil(img_size[0]/scale[\"stride\"]), ceil(img_size[1]/scale[\"stride\"]))  for scale in anchor_info]\n",
        "    num_proposals = num_anchors * sum([i[0]*i[1] for i in feature_maps])\n",
        "    anchors = np.zeros((num_proposals, 4))\n",
        "\n",
        "    counter = 0\n",
        "    for idx, f in enumerate(feature_maps):\n",
        "        scaler = anchor_info[idx][\"stride\"]\n",
        "        for h in range(f[1]):\n",
        "            cy = (h + 0.5) * scaler\n",
        "            for w in range(f[0]):\n",
        "                cx = (w + 0.5) * scaler\n",
        "                for s in anchor_info[idx][\"anchors\"]:\n",
        "                    anchors[counter,:] = [cx, cy, s, s]\n",
        "                    counter += 1\n",
        "\n",
        "    priors = torch.Tensor(anchors).view(-1, 4)\n",
        "    if run_gpu:\n",
        "        priors = priors.to(device)\n",
        "    return priors\n",
        "\n",
        "def iou(box_a, box_b):\n",
        "    \"\"\"\n",
        "    return iou of a and b, numpy version for data augenmentation\n",
        "    \"\"\"\n",
        "    inter = intersect(box_a, box_b)\n",
        "    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n",
        "              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n",
        "    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n",
        "              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n",
        "    union = area_a + area_b - inter\n",
        "    return inter / union  # [A,B]\n",
        "\n",
        "\n",
        "def intersect(box_a, box_b):\n",
        "    \"\"\" We resize both tensors to [A,B,2] without new malloc:\n",
        "    [A,2] -> [A,1,2] -> [A,B,2]\n",
        "    [B,2] -> [1,B,2] -> [A,B,2]\n",
        "    Then we compute the area of intersect between box_a and box_b.\n",
        "    Args:\n",
        "      box_a: (tensor) bounding boxes, Shape: [A,4].\n",
        "      box_b: (tensor) bounding boxes, Shape: [B,4].\n",
        "    Return:\n",
        "      (tensor) intersection area, Shape: [A,B].\n",
        "    \"\"\"\n",
        "    A = box_a.size(0)\n",
        "    B = box_b.size(0)\n",
        "    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n",
        "                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n",
        "    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n",
        "                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n",
        "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
        "    return inter[:, :, 0] * inter[:, :, 1]\n",
        "\n",
        "\n",
        "def decode_boxes(box, priors):\n",
        "    centers = box[:,0:2] * variances[1] * priors[:,2:4] + priors[:,0:2]\n",
        "    lengths = priors[:,2:4] * torch.exp(box[:,2:4] * variances[0])\n",
        "    boxes = torch.cat((centers, lengths), dim=1)\n",
        "    return _to_min_max_form(boxes)\n",
        "\n",
        "\n",
        "def _to_min_max_form(boxes):\n",
        "    converted = (boxes[:, :2] - boxes[:, 2:]/2, boxes[:, :2] + boxes[:, 2:]/2)\n",
        "    return torch.cat(converted, dim=1)\n",
        "\n",
        "\n",
        "def _to_center_length_form(boxes):\n",
        "    converted = ((boxes[:, 2:] + boxes[:, :2])/2, boxes[:, 2:] - boxes[:, :2])\n",
        "    return torch.cat(converted, dim=1)\n",
        "\n",
        "def draw_saliency(model, imgs, init_img):\n",
        "    w, h = init_img.size\n",
        "    px = 1/plt.rcParams['figure.dpi']\n",
        "#     fig = plt.figure(frameon=False)\n",
        "    fig, ax = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(1.5*w*px, h*px)\n",
        "\n",
        "    imgs.requires_grad_()\n",
        "    outs = model.fpn(model.backbone(imgs))\n",
        "    prob = model.p2_pred[:-1](outs[0]) + model.p4_pred[:-1](outs[2]) + model.p6_pred[:-1](outs[4])\n",
        "    prob.backward()\n",
        "\n",
        "    saliency, _ = torch.max(imgs.grad.data.abs(), dim=1)\n",
        "    saliency = saliency.reshape(init_img.size[1], init_img.size[0])\n",
        "\n",
        "    # Visualize the image and the saliency map\n",
        "    ax[0].imshow(init_img)\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(saliency.cpu(), cmap='hot')\n",
        "    ax[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    fig.suptitle('Prob:' + str(torch.sigmoid(prob / 3).data.item()))\n",
        "    plt.show()\n",
        "\n",
        "def draw_boxes(img, box, save_dir=None):\n",
        "    w, h = img.size\n",
        "    px = 1/plt.rcParams['figure.dpi']\n",
        "    fig = plt.figure(frameon=False)\n",
        "    fig.set_size_inches(w*px, h*px)\n",
        "    plt.imshow(img)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    for idx in range(box.shape[0]):\n",
        "        # Create a Rectangle patch\n",
        "        box_len = min(box[idx,2]-box[idx,0], box[idx,3]-box[idx,1])\n",
        "        rect = Rectangle(\n",
        "            (box[idx,0], box[idx,1]),\n",
        "            box[idx,2]-box[idx,0],\n",
        "            box[idx,3]-box[idx,1],\n",
        "            linewidth=1,edgecolor='r',facecolor='none')\n",
        "        # Add the patch to the Axes\n",
        "        ax.add_patch(rect)\n",
        "    if save_dir is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(save_dir)\n",
        "\n",
        "\n",
        "def draw_different_boxes(img, box_arr, conf_arr, titles):\n",
        "    w, h = img.size\n",
        "    wsize = 3\n",
        "    if len(box_arr) % wsize == 0:\n",
        "        hsize = (len(box_arr) // wsize)\n",
        "    else:\n",
        "        hsize = (len(box_arr) // wsize + 1)\n",
        "    w = (w + 100) * wsize\n",
        "    h = (h + 50) * hsize\n",
        "\n",
        "    px = 1/plt.rcParams['figure.dpi']\n",
        "    f, axarr = plt.subplots(hsize, wsize)\n",
        "    f.set_size_inches(w*px, h*px)\n",
        "\n",
        "    colors = [\"r\"] # \"b\", \"orange\", \"green\", \"pink\", \"yellow\"\n",
        "\n",
        "    for j, box in enumerate(box_arr):\n",
        "        widx = j % wsize\n",
        "        hidx = j // wsize\n",
        "        conf = conf_arr[j]\n",
        "        if hsize == 1:\n",
        "            ax = axarr[j]\n",
        "        else:\n",
        "            ax = axarr[hidx, widx]\n",
        "        ax.imshow(img)\n",
        "        ax.title.set_text(titles[j])\n",
        "        color = colors[j%len(colors)]\n",
        "        for idx in range(box.shape[0]):\n",
        "            # Create a Rectangle patch\n",
        "            box_len = min(box[idx,2]-box[idx,0], box[idx,3]-box[idx,1])\n",
        "            rect = Rectangle(\n",
        "                (box[idx,0], box[idx,1]),\n",
        "                box[idx,2]-box[idx,0], box[idx,3]-box[idx,1],\n",
        "                linewidth=2, edgecolor=color, facecolor='none'\n",
        "            )\n",
        "            # Add the patch to the Axes\n",
        "            ax.add_patch(rect)\n",
        "            cx = box[idx,0]\n",
        "            cy = box[idx,1] + 12\n",
        "            ax.text(cx, cy, str(conf[idx])[:5])\n",
        "            if hsize == 1:\n",
        "                axarr[j] = ax\n",
        "            else:\n",
        "                axarr[hidx, widx] = ax\n",
        "    plt.show()\n",
        "\n",
        "class RetinaFace(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone=\"resnet50\",\n",
        "        img_size=[640, 640]\n",
        "    ):\n",
        "        super(RetinaFace, self).__init__()\n",
        "        self.num_anchors = 3\n",
        "        self.anchor_info = [\n",
        "            {\"stride\": 4, \"anchors\": [16, 20.16, 25.40]},\n",
        "            {\"stride\": 8, \"anchors\": [32, 40.32, 50.80]},\n",
        "            {\"stride\": 16, \"anchors\": [64, 80.63, 101.59]},\n",
        "            {\"stride\": 32, \"anchors\": [128, 161.26, 203.19]},\n",
        "            {\"stride\": 64, \"anchors\": [256, 322.54, 406.37]}\n",
        "        ]\n",
        "\n",
        "        if img_size is None or img_size[0] < 0 or img_size[1] < 0:\n",
        "            self.priors = None # no need to store priors if only prediction will be made\n",
        "        else:\n",
        "            self.priors = _get_priorboxes(self.num_anchors, self.anchor_info, img_size)\n",
        "\n",
        "        self.backbone = Backbone(backbone=backbone)\n",
        "        in_size = self.backbone.in_sizes\n",
        "        self.fpn = FeaturePyramid(in_sizes=in_size, out_size=256)\n",
        "        self.context_module = ContextModule(in_size=256, out_size=256)\n",
        "        self.heads2 = nn.ModuleList([\n",
        "            HeadGetter(256, 2),\n",
        "            HeadGetter(256, 4),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        p_vals = self.backbone(x)\n",
        "        p_vals = self.fpn(p_vals)\n",
        "        p_vals = self.context_module(p_vals)\n",
        "        class_vals = self.heads2[0](p_vals)\n",
        "        bbox_vals = self.heads2[1](p_vals)\n",
        "        return class_vals, bbox_vals\n",
        "\n",
        "\n",
        "    def get_loss(self, x, y):\n",
        "        class_vals, bbox_vals = self(x); cls_res = F.softmax(class_vals, dim=2)\n",
        "        N, P, T = class_vals.shape\n",
        "        lposcls = 0; lnegcls = 0; lbox = 0; clsNeg = 0; boxN = 0\n",
        "\n",
        "        for n in range(N):\n",
        "            gt, pos_idx, neg_idx = encode_gt_and_get_indices(\n",
        "                y[n], self.priors, cls_res[n,:,0], pos_iou, neg_iou)\n",
        "\n",
        "            if pos_idx is None or len(pos_idx) < 1:\n",
        "                continue\n",
        "\n",
        "            # cls loss\n",
        "            pos_lcls = F.cross_entropy(\n",
        "                class_vals[n,pos_idx,:],\n",
        "                torch.ones(len(pos_idx), dtype=torch.long).to(device),\n",
        "                reduction='sum'\n",
        "            )\n",
        "            lposcls += pos_lcls\n",
        "\n",
        "            neg_lcls = F.cross_entropy(\n",
        "                class_vals[n,neg_idx,:],\n",
        "                torch.zeros(len(neg_idx), dtype=torch.long).to(device),\n",
        "                reduction='sum'\n",
        "            )\n",
        "            lnegcls += neg_lcls\n",
        "            clsNeg += len(neg_idx)\n",
        "\n",
        "            # box loss\n",
        "            lbox += F.smooth_l1_loss(bbox_vals[n,pos_idx,:], gt[:,0:4], reduction='sum')\n",
        "            boxN += len(pos_idx)\n",
        "\n",
        "        boxN = max(1, boxN); clsNeg = max(1, clsNeg)\n",
        "        return (lposcls + lnegcls) / boxN, lbox/boxN\n",
        "\n",
        "    def train_model(\n",
        "        self, det_data, epochs, start_epoch=1, weight_decay=0.0005,\n",
        "        init_lr=0.001, lr_changes=[3, 25, 40], log_file=None, save_dir=None\n",
        "    ):\n",
        "        optimizer = optim.SGD(self.parameters(), lr=init_lr, momentum=0.9, weight_decay=weight_decay)\n",
        "        for e in range(start_epoch, epochs+1):\n",
        "            lr = self.adjust_learning_rate(optimizer, e, init_lr, lr_changes)\n",
        "            x, y = det_data.forward(restart=True)\n",
        "            curr_batch = 0; total_imgs = len(det_data.imgs_path)\n",
        "\n",
        "            while x is not None and y is not None:\n",
        "                curr_batch += x.shape[0]\n",
        "                optimizer.zero_grad()\n",
        "                lcls, lbox = self.get_loss(x, y)\n",
        "                total_loss = lcls + lambda1 * lbox\n",
        "                total_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                self.print_losses(\n",
        "                    e, curr_batch, total_imgs, lr, lcls.data.item(), lbox.data.item(), log_file=log_file\n",
        "                )\n",
        "                x, y = det_data.forward()\n",
        "\n",
        "            if save_dir is not None:\n",
        "                self.save_model(save_dir + \"model_epoch\" + str(e) + \".pth\")\n",
        "\n",
        "\n",
        "    def predict_image(self, x, nms_thold=0.4, conf_thold=0.5, topk=5000, keep_topk=None, filter=True):\n",
        "        N, C, H, W = x.shape\n",
        "        priors = _get_priorboxes(self.num_anchors, self.anchor_info, [W, H])\n",
        "        with torch.no_grad():\n",
        "            class_vals, bbox_vals = self(x)\n",
        "        bbox_vals = decode_boxes(bbox_vals[0,:,:], priors)\n",
        "        scores = F.softmax(class_vals, dim=2)[0,:,1]\n",
        "\n",
        "        if not filter:\n",
        "            return scores.cpu().data.numpy(), bbox_vals.cpu().data.numpy()\n",
        "\n",
        "        # confidence filtering\n",
        "        conf_pass = torch.where(scores > conf_thold)[0]\n",
        "        bbox_vals = bbox_vals[conf_pass,:]\n",
        "        scores = scores[conf_pass]\n",
        "        # Keep top-k\n",
        "        tops = torch.argsort(scores, descending=True)[:topk]\n",
        "        bbox_vals = bbox_vals[tops,:]\n",
        "        scores = scores[tops]\n",
        "        # nms filtering\n",
        "        nms_pass = nms(scores, bbox_vals, nms_thold)\n",
        "        bbox_vals = bbox_vals[nms_pass,:]\n",
        "        scores = scores[nms_pass]\n",
        "        # last keep-topk filtering\n",
        "        if keep_topk is not None and len(scores) > keep_topk:\n",
        "            most_tops = torch.argsort(scores, descending=True)[:keep_topk]\n",
        "            bbox_vals = bbox_vals[most_tops,:]\n",
        "            scores = scores[most_tops]\n",
        "\n",
        "        return scores.cpu().data.numpy(), bbox_vals.cpu().data.numpy()\n",
        "\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "\n",
        "    def adjust_learning_rate(self, optimizer, epoch, init_lr, lr_changes):\n",
        "        if epoch < lr_changes[0]:\n",
        "            lr = init_lr\n",
        "        elif lr_changes[0] <= epoch < lr_changes[1]:\n",
        "            lr = 10 * init_lr\n",
        "        elif lr_changes[1] <= epoch < lr_changes[2]:\n",
        "            lr = init_lr\n",
        "        else:\n",
        "            lr = init_lr / 10\n",
        "\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        return lr\n",
        "\n",
        "\n",
        "    def print_losses(self, epoch, batch, total, lr, lcls, lbox, log_file=None):\n",
        "        to_print = \"E: \" + str(epoch)\n",
        "        to_print +=  \" & B: \" + str(batch) + \"/\" + str(total)\n",
        "        to_print += \" & LR: \" + str(lr)[:min(6, len(str(lr)))]\n",
        "        to_print += \" ---> Cls: \" + str(lcls)[:min(6, len(str(lcls)))]\n",
        "        to_print += \" | Box: \" + str(lbox)[:min(6, len(str(lbox)))]\n",
        "        print(to_print)\n",
        "        if log_file is not None:\n",
        "            f = open(log_file, \"a\")\n",
        "            f.write(to_print + \"\\n\")\n",
        "            f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXtidZ4_Ly72"
      },
      "source": [
        "### Text generation utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4ierktbMHUw"
      },
      "outputs": [],
      "source": [
        "# AUXILIARY FUNCTIONS\n",
        "\n",
        "# Textual part\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove newline characters\n",
        "    text = text.replace('\\n', ' ')\n",
        "\n",
        "    # Remove sequences of hyphens\n",
        "    text = re.sub(r'-+', '', text)\n",
        "\n",
        "    # Remove leading and trailing spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def call_model(prompt, api_key=None, use_local_model=False):\n",
        "    if use_local_model:\n",
        "        from llama_cpp import Llama\n",
        "        llm = Llama(model_path='./llama.cpp/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf')\n",
        "        output = llm(prompt, max_tokens=300, echo=True, temperature=0.2)\n",
        "        return clean_text(output[\"choices\"][0][\"text\"])\n",
        "    else:\n",
        "        # Tu clave API de Hugging Face\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\"\n",
        "        }\n",
        "        API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "        payload = {\"inputs\": prompt}\n",
        "\n",
        "        response = requests.post(API_URL, headers=headers, json=payload)\n",
        "        return clean_text(response.json()[0][\"generated_text\"])\n",
        "\n",
        "def process_book(directory_name, input_file, book_id):\n",
        "\n",
        "    if os.path.exists(f\"booknlp_files/{directory_name}/{book_id}.book\"):\n",
        "        return proc(f\"booknlp_files/{directory_name}/{book_id}.book\")\n",
        "\n",
        "    model_params={\n",
        "        \"pipeline\":\"entity,quote,supersense,event,coref\",\n",
        "        \"model\":\"big\"\n",
        "    }\n",
        "\n",
        "    booknlp=BookNLP(\"en\", model_params)\n",
        "\n",
        "    # Output directory to store resulting files in\n",
        "    output_directory= f\"booknlp_files/{directory_name}/\"\n",
        "\n",
        "    booknlp.process(input_file, output_directory, book_id)\n",
        "\n",
        "    return proc(f\"booknlp_files/{directory_name}/{book_id}.book\")\n",
        "\n",
        "def proc(filename):\n",
        "    with open(filename) as file:\n",
        "        data=json.load(file)\n",
        "    return data\n",
        "\n",
        "def get_counter_from_dependency_list(dep_list):\n",
        "    counter=Counter()\n",
        "    for token in dep_list:\n",
        "        term=token[\"w\"]\n",
        "        tokenGlobalIndex=token[\"i\"]\n",
        "        counter[term]+=1\n",
        "    return counter\n",
        "\n",
        "def create_character_data(data, printTop):\n",
        "    character_data = {}\n",
        "    for character in data[\"characters\"]:\n",
        "\n",
        "        agentList=character[\"agent\"]\n",
        "        patientList=character[\"patient\"]\n",
        "        possList=character[\"poss\"]\n",
        "        modList=character[\"mod\"]\n",
        "\n",
        "        character_id=character[\"id\"]\n",
        "        count=character[\"count\"]\n",
        "\n",
        "        referential_gender_distribution=referential_gender_prediction=\"unknown\"\n",
        "\n",
        "        if character[\"g\"] is not None and character[\"g\"] != \"unknown\":\n",
        "            referential_gender_distribution=character[\"g\"][\"inference\"]\n",
        "            referential_gender=character[\"g\"][\"argmax\"]\n",
        "\n",
        "        mentions=character[\"mentions\"]\n",
        "        proper_mentions=mentions[\"proper\"]\n",
        "        max_proper_mention=\"\"\n",
        "\n",
        "        #Let's create some empty lists that we can append to.\n",
        "        poss_items = []\n",
        "        agent_items = []\n",
        "        patient_items = []\n",
        "        mod_items = []\n",
        "\n",
        "        # just print out information about named characters\n",
        "        if len(mentions[\"proper\"]) > 0:\n",
        "            max_proper_mention=mentions[\"proper\"][0][\"n\"]\n",
        "            for k, v in get_counter_from_dependency_list(possList).most_common(printTop):\n",
        "                poss_items.append((v,k))\n",
        "\n",
        "            for k, v in get_counter_from_dependency_list(agentList).most_common(printTop):\n",
        "                agent_items.append((v,k))\n",
        "\n",
        "            for k, v in get_counter_from_dependency_list(patientList).most_common(printTop):\n",
        "                patient_items.append((v,k))\n",
        "\n",
        "            for k, v in get_counter_from_dependency_list(modList).most_common(printTop):\n",
        "                mod_items.append((v,k))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # print(character_id, count, max_proper_mention, referential_gender)\n",
        "            character_data[character_id] = {\"id\": character_id,\n",
        "                                  \"count\": count,\n",
        "                                  \"max_proper_mention\": max_proper_mention,\n",
        "                                  \"referential_gender\": referential_gender,\n",
        "                                  \"possList\": poss_items,\n",
        "                                  \"agentList\": agent_items,\n",
        "                                  \"patientList\": patient_items,\n",
        "                                  \"modList\": mod_items\n",
        "                                 }\n",
        "\n",
        "    return character_data\n",
        "\n",
        "def generate_attributes(text, character_list):\n",
        "\n",
        "    # Load the English NLP model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the text with spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Initialize a dictionary to store descriptions for each character\n",
        "    character_descriptions = {c['names'][0]: {'all_names': c['names'], 'gender': c['gender'], 'attributes': []} for c in character_list}\n",
        "\n",
        "    # Iterate through named entities in the document\n",
        "    for ent in doc.ents:\n",
        "        for character in character_list:\n",
        "            character_names = character[\"names\"]\n",
        "            this_character_descriptions = []\n",
        "            if ent.text in character_names:\n",
        "                # Find the sentences containing any of the character names\n",
        "                sentences = [sent.text for sent in doc.sents if any(name in sent.text for name in character_names)]\n",
        "                # Extract descriptions from the context\n",
        "                descriptions = []\n",
        "                for sentence in sentences:\n",
        "                    # Example: Extract adjectives describing the character\n",
        "                    for token in nlp(sentence):\n",
        "                        if token.pos_ == \"ADJ\":\n",
        "                            descriptions.append(token.text)\n",
        "                    # Add more sophisticated logic here for detailed extraction\n",
        "                this_character_descriptions += descriptions\n",
        "\n",
        "            for description in this_character_descriptions:\n",
        "                if description not in character_descriptions[character_names[0]]['attributes']:\n",
        "                    character_descriptions[character_names[0]]['attributes'].append(description)\n",
        "\n",
        "    return character_descriptions\n",
        "\n",
        "def generate_descriptions(characters, hb_api_key, use_local_model=False):\n",
        "\n",
        "    descriptions = {}\n",
        "\n",
        "    for character in characters:\n",
        "\n",
        "        name = characters[character]['all_names'][0]\n",
        "        gender = characters[character]['gender']\n",
        "        attributes = characters[character]['attributes']\n",
        "\n",
        "        print(f\"Generating description for {name}\")\n",
        "\n",
        "        if attributes:\n",
        "\n",
        "            prompt = f'''Given the following name of a character, their gender and a series of attributes (some of them physical, some of them not), please write a short, physical description of the character. You can use the attributes provided or come up with your own as long as they make sense.\n",
        "            It is very important that you also specify the clothes that the character is wearing. Again, come up with the clothes according to the character's physical attributes, so that it makes sense for them to wear them.\n",
        "            The description must not include the name of the character: it must be something like: \"A tall man with big, blue ayes and browm hair and pale skin... wearing a black suit and a red tie.\"\n",
        "\n",
        "            CHARACTER NAME: {name}\n",
        "            GENDER: {gender}\n",
        "            ATTRIBUTES: {\",\".join(attributes)}\n",
        "\n",
        "            It is important for you to stick to the physical attributes of the character, since this description will be used in order to generate a portrait of the character: their physical appearance, not their personality or background.\n",
        "\n",
        "            Please, reply only with the description sentence.\n",
        "            '''\n",
        "\n",
        "        else:\n",
        "\n",
        "            prompt = f'''Given the following name of a character and their gender, please write a short, physical description of the character. Make up the description based on the name and gender of the character.\n",
        "            It is very important that you also specify the clothes that the character is wearing. You can come up with the clothes according to the character's physical attributes, so that it makes sense for them to wear them.\n",
        "            The description must not include the name of the character: it must be something like: \"A tall man with big, blue ayes and browm hair and pale skin... wearing a black suit and a red tie.\"\n",
        "\n",
        "            CHARACTER NAME: {name}\n",
        "            GENDER: {gender}\n",
        "\n",
        "            It is important for you to stick to the physical attributes of the character, since this description will be used in order to generate a portrait of the character: their physical appearance, not their personality or background.\n",
        "\n",
        "            Please, reply only with the description sentence.'''\n",
        "\n",
        "        description = call_model(prompt, hb_api_key, use_local_model)\n",
        "\n",
        "        if \"Please, reply only with the description sentence.\" in description:\n",
        "            description = description.split(\"Please, reply only with the description sentence.\")[1].strip()\n",
        "        else:\n",
        "            description = description.strip()\n",
        "        if \"GENDER:\" in description:\n",
        "            description = description.split(\"GENDER:\")[1].split(' ')[1].strip()\n",
        "\n",
        "        descriptions[name] = description\n",
        "\n",
        "    return descriptions\n",
        "\n",
        "def get_character_ids(entities_path, characters, cont=0):\n",
        "\n",
        "    df_entities = pd.read_csv(entities_path, delimiter=\"\\t\")\n",
        "\n",
        "    n_characters = len(characters)\n",
        "\n",
        "    for index, entity in df_entities.iterrows():\n",
        "        name = entity['text']\n",
        "        coref = entity['COREF']\n",
        "        for character in characters:\n",
        "            if 'coref' not in character:\n",
        "                if name in character['names']:\n",
        "                    character['coref'] = coref\n",
        "                    cont += 1\n",
        "                    break\n",
        "        if cont == n_characters:\n",
        "            break\n",
        "\n",
        "    return characters\n",
        "\n",
        "def construct_quote_to_character(directory_name, book_id, characters):\n",
        "\n",
        "    df_quotes = pd.read_csv(f\"booknlp_files/{directory_name}/{book_id}.quotes\", delimiter=\"\\t\")\n",
        "    df_entities = pd.read_csv(f\"booknlp_files/{directory_name}/{book_id}.entities\", delimiter=\"\\t\")\n",
        "\n",
        "    quotes = {}\n",
        "\n",
        "    for index, quote in df_quotes.iterrows():\n",
        "        text = quote['quote'].strip().replace(\" !\", \"!\").replace(\" ?\", \"?\").replace(\" .\", \".\").replace(\" ,\", \",\")\n",
        "        char_id = quote['char_id']\n",
        "        for character in characters:\n",
        "            if char_id == character['coref']:\n",
        "                quotes[text] = (char_id, character['names'][0])\n",
        "                break\n",
        "        else:\n",
        "            char_name = df_entities[df_entities.COREF == char_id]['text']\n",
        "            if len(char_name) > 10: # We consider this a character that deserves a panel\n",
        "              quotes[text] = (char_id, char_name)\n",
        "            else:\n",
        "              quotes[text] = (char_id, None)\n",
        "\n",
        "    return quotes\n",
        "\n",
        "def split_into_paragraphs(input_file):\n",
        "    with open(input_file) as file:\n",
        "        text = file.read()\n",
        "    # Use a regular expression to split the text wherever there are two or more newline characters\n",
        "    paragraphs = re.split(r'\\n{2,}', text)\n",
        "    # Remove any residual leading or trailing whitespace from each paragraph\n",
        "    return [re.sub(r'\\n\\s+', ' ', paragraph).strip() for paragraph in paragraphs]\n",
        "\n",
        "def get_characters_in_scene(paragraph, characters, descriptions, quotes):\n",
        "    # Initialize an empty list to store the characters found in the scene\n",
        "    characters_in_scene = []\n",
        "    aux = []\n",
        "    is_quote = False\n",
        "    character_names = []\n",
        "    for c in characters:\n",
        "      character_names += c['names']\n",
        "\n",
        "    # Iterate over the characters to check if they are mentioned in the paragraph\n",
        "    for character in characters:\n",
        "        # Check if the character's name or any of their aliases are mentioned in the paragraph\n",
        "        for alias in character['names']:\n",
        "            if alias in paragraph:\n",
        "                characters_in_scene.append({'name': alias, 'description': descriptions[character['names'][0]]})\n",
        "                aux.append(alias)\n",
        "                break\n",
        "\n",
        "    # Iterate over the quotes to check if the character is speaking in the paragraph\n",
        "    for quote in quotes:  # TODO: Begin from the point in which the story is, not be confused with past quotes\n",
        "        if quote in paragraph:\n",
        "            is_quote = True\n",
        "            if quotes[quote][1] is not None:\n",
        "                if quotes[quote][1] in character_names:\n",
        "                  if quotes[quote][1] not in aux:\n",
        "                    characters_in_scene.append({'name': quotes[quote][1], 'description': descriptions[quotes[quote][1]]})\n",
        "                    break\n",
        "                else:\n",
        "                  characters_in_scene.append({'name': quotes[quote][1], 'description': quotes[quote][1]})\n",
        "                  break\n",
        "\n",
        "    if '[NARRATOR]' in [c['names'][0] for c in characters] and '[NARRATOR]' not in aux:\n",
        "        characters_in_scene.append({'name': '[NARRATOR]', 'description': descriptions['[NARRATOR]']})\n",
        "\n",
        "    # Return the list of characters found in the scene\n",
        "    return characters_in_scene, is_quote\n",
        "\n",
        "def generate_scene_from_paragraph(paragraph, characters, descriptions, quotes, hb_api_key, use_local_model=False, previous_scene=None):\n",
        "\n",
        "    characters_in_scene, is_quote = get_characters_in_scene(paragraph, characters, descriptions, quotes)\n",
        "\n",
        "    print(\"GENERATING SCENE FOR PARAGRAPH:\")\n",
        "    print(paragraph)\n",
        "    print(\"CHARACTERS IN SCENE:\")\n",
        "    print([c['name'] for c in characters_in_scene])\n",
        "\n",
        "    characters_str = \"\"\n",
        "\n",
        "    for character in characters_in_scene:\n",
        "        characters_str += f\"{character['name']}\"\n",
        "        if character['description']:\n",
        "            characters_str += f\": {character['description']}\"\n",
        "        characters_str += \"\\n\"\n",
        "\n",
        "    if previous_scene:\n",
        "\n",
        "        prompt = f'''I am going to give you a paragraph extracted from a tale, and I want you to extract a prompt useful for a text to image model (DallE, Stable Diffusion, Midjourney) that represents a scene.\n",
        "    Attached to the paragraph, you also have a description of the characters that are mentioned in it, so that you use it in the prompt if you think it is necessary.\n",
        "    Do not include the name of the characters in the prompt: only their description is necessary for the model to generate the image.\n",
        "    Keep the prompt as short and descriptive as possible, ensuring the result will be a great image that encapsules the scene that the paragraph is describing.\n",
        "    IMPORTANT: If the paragraph is a dialogue, just stick to a close up of the speaker: no text is required for the scene, only the description for the image.\n",
        "\n",
        "    Please, reply with the prompt only, without any additional text.\n",
        "\n",
        "    PARAGRAPH:\n",
        "\n",
        "    {paragraph}\n",
        "\n",
        "    CHARACTERS:\n",
        "    {characters_str}\n",
        "\n",
        "    PREVIOUS SCENE:\n",
        "    {previous_scene}\n",
        "\n",
        "    IMAGE PROMPT:'''\n",
        "\n",
        "    else:\n",
        "\n",
        "        prompt = f'''I am going to give you a paragraph extracted from a tale, and I want you to extract a prompt useful for a text to image model (DallE, Stable Diffusion, Midjourney) that represents a scene.\n",
        "    Attached to the paragraph, you also have a description of the characters that are mentioned in it, so that you use it in the prompt if you think it is necessary.\n",
        "    Do not include the name of the characters in the prompt: only their description is necessary for the model to generate the image.\n",
        "    Keep the prompt as short and descriptive as possible, ensuring the result will be a great image that encapsules the scene that the paragraph is describing.\n",
        "    IMPORTANT: If the paragraph is a dialogue, just stick to a close up of the speaker: no text is required for the scene, only the description for the image.\n",
        "\n",
        "    Please, reply with the prompt only, without any additional text.\n",
        "\n",
        "    PARAGRAPH:\n",
        "\n",
        "    {paragraph}\n",
        "\n",
        "    CHARACTERS:\n",
        "    {characters_str}\n",
        "\n",
        "    IMAGE PROMPT:'''\n",
        "\n",
        "    scene = call_model(prompt, hb_api_key, use_local_model)\n",
        "\n",
        "    if \"IMAGE PROMPT:\" in scene:\n",
        "        scene = scene.split(\"IMAGE PROMPT:\")[1].strip()\n",
        "    else:\n",
        "        scene = scene.strip()\n",
        "\n",
        "    return scene, is_quote\n",
        "\n",
        "def generate_text_from_paragraph(paragraph, hb_api_key, use_local_model=False):\n",
        "\n",
        "    prompt = f'''I am going to give you a paragraph extracted from a tale. I have an image that represents the scene, and what I want you to do is give me the piece of text that will be attached to it, kind of like a comic book.\n",
        "Give me the little text that would suit the panel. Think of it as a comic book panel, where the text is a short sentence that complements the image, but doesn't repeat what is already shown in it.\n",
        "\n",
        "Please, reply with the text only, without any additional text.\n",
        "\n",
        "PARAGRAPH:\n",
        "\n",
        "{paragraph}\n",
        "\n",
        "TEXT:'''\n",
        "\n",
        "    text = call_model(prompt, hb_api_key, use_local_model)\n",
        "\n",
        "    if \"TEXT:\" in text:\n",
        "        text = text.split(\"TEXT:\")[1].strip()\n",
        "    else:\n",
        "        text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def generate_textual_scene(paragraph, characters, descriptions, quotes, hb_api_key, use_local_model=False, previous_scene=None):\n",
        "    prompt, is_quote = generate_scene_from_paragraph(paragraph, characters, descriptions, quotes, hb_api_key, use_local_model, previous_scene)\n",
        "    text = generate_text_from_paragraph(paragraph, hb_api_key, use_local_model)\n",
        "    return {'prompt': prompt, 'text': text, 'is_quote': is_quote}\n",
        "\n",
        "# UTILITY FUNCTIONS\n",
        "\n",
        "# Textual part\n",
        "\n",
        "def extract_characters(directory_name, input_file, book_id):\n",
        "\n",
        "    data = process_book(directory_name, input_file, book_id)\n",
        "    character_data = create_character_data(data, 1)\n",
        "    character_list = {a['max_proper_mention']: a['referential_gender'] for a in character_data.values()}\n",
        "\n",
        "    with open(f\"booknlp_files/{directory_name}/{book_id}.book.html\") as file:\n",
        "        data = file.read()\n",
        "\n",
        "    character_other_names = []\n",
        "    for a in data.split(\"<h2>Named characters</h2>\")[1].split(\"<p>\")[0].split(\"<br />\"):\n",
        "        aux = a.replace(\"\\n\", \"\")\n",
        "        if aux != \"\":\n",
        "            if \"(\" not in aux:\n",
        "                main_name = aux.split(\" \")[1]\n",
        "            else:\n",
        "                main_name = \" \".join(aux.split(\" (\")[0].split(\" \")[1:])\n",
        "            character_other_names.append([main_name])\n",
        "\n",
        "    named_characters = []\n",
        "\n",
        "    cont = 0\n",
        "    for c in character_other_names:\n",
        "        if c[0] == \"[NARRATOR]\":\n",
        "            named_characters.append({'names': c, 'gender': 'unknown', 'coref': 0})\n",
        "            cont = 1\n",
        "        elif c[0] in character_list:\n",
        "            named_characters.append({'names': c, 'gender': character_list[c[0]]})\n",
        "        else:\n",
        "            named_characters.append({'names': c, 'gender': 'unknown'})\n",
        "\n",
        "    named_characters = get_character_ids(f\"booknlp_files/{directory_name}/{book_id}.entities\", named_characters, cont)\n",
        "\n",
        "    return named_characters\n",
        "\n",
        "def extract_descriptions(input_file, named_characters, hb_api_key, use_local_model=False):\n",
        "\n",
        "    with open(input_file) as file:\n",
        "        book_text = file.read()\n",
        "\n",
        "    print(\"Generating attributes...\")\n",
        "    characters = generate_attributes(book_text, named_characters)\n",
        "\n",
        "    print(\"Generating descriptions...\")\n",
        "    descriptions = generate_descriptions(characters, hb_api_key, use_local_model)\n",
        "\n",
        "    return descriptions\n",
        "\n",
        "def generate_textual_scenes(paragraphs, characters, descriptions, quotes, hb_api_key, use_local_model=False, previous_scene=None):\n",
        "    scenes = []\n",
        "    for paragraph in paragraphs:\n",
        "        scene = generate_textual_scene(paragraph, characters, descriptions, quotes, hb_api_key, use_local_model, previous_scene)\n",
        "        previous_scene = scene['prompt']\n",
        "        scenes.append(scene)\n",
        "    return scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSWspSkZwMVi"
      },
      "source": [
        "### Image generation utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elvBBUCewKTE"
      },
      "outputs": [],
      "source": [
        "# Image part\n",
        "\n",
        "def textsize(text, font):\n",
        "    im = Image.new(mode=\"P\", size=(0, 0))\n",
        "    draw = ImageDraw.Draw(im)\n",
        "    _, _, width, height = draw.textbbox((0, 0), text=text, font=font)\n",
        "    return width, height\n",
        "\n",
        "def create_book_cover(title: str, author: str, file_path: str, font_path: str):\n",
        "    # Create a blank A4 image with a black background\n",
        "    img = Image.new('RGB', (2480, 3508), color='black')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Set the title and author fonts\n",
        "    title_font = ImageFont.truetype(font_path, 120)\n",
        "    author_font = ImageFont.truetype(font_path, 100)\n",
        "    c2b_font = ImageFont.truetype(font_path, 80)\n",
        "\n",
        "    # Calculate text width and height to center the text\n",
        "    title_width, title_height = textsize(title, font=title_font)\n",
        "    author_width, author_height = textsize(author, font=author_font)\n",
        "    c2b_width, c2b_height = textsize(\"Adapted by Book2Comic\", font=c2b_font)\n",
        "\n",
        "    # Calculate positions\n",
        "    title_x = (img.width - title_width) / 2\n",
        "    title_y = (img.height / 2) - title_height\n",
        "    author_x = (img.width - author_width) / 2\n",
        "    author_y = (img.height / 2) + (author_height / 2)\n",
        "    c2b_x = (img.width - c2b_width) / 2\n",
        "    c2b_y = (img.height / 2) + (c2b_height / 2)\n",
        "\n",
        "    # Draw text on the image\n",
        "    draw.text((title_x, title_y), title, font=title_font, fill=\"white\")\n",
        "    draw.text((author_x, author_y), author, font=author_font, fill=\"white\")\n",
        "    draw.text((c2b_x, c2b_y), \"Adapted by Book2Comic\", font=c2b_font, fill=\"white\")\n",
        "\n",
        "    # Save the image\n",
        "    img.save(file_path, 'PNG')\n",
        "\n",
        "def wrap_text(text, font, max_width):\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = words[0]\n",
        "\n",
        "    for word in words[1:]:\n",
        "        test_line = f\"{current_line} {word}\"\n",
        "        test_width, _ = textsize(test_line, font)\n",
        "        if test_width <= max_width:\n",
        "            current_line = test_line\n",
        "        else:\n",
        "            lines.append(current_line)\n",
        "            current_line = word\n",
        "\n",
        "    lines.append(current_line)  # Add the last line\n",
        "    return lines\n",
        "\n",
        "def create_comic_grid(images_paths, dialogues, font_path, save_path='comic.png', grid_size=(3,2), margin=20, min_text_height=80):\n",
        "    num_filas, num_columnas = grid_size\n",
        "    images = [Image.open(path) for path in images_paths]\n",
        "    ancho_img, alto_img = images[0].size\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(font_path, 24)\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    text_heights = [min_text_height] * len(images)\n",
        "    wrapped_text = []\n",
        "\n",
        "    for index, text in enumerate(dialogues):\n",
        "        lines = wrap_text(text, font, ancho_img - margin)\n",
        "        wrapped_text.append(\"\\n\".join(lines))\n",
        "        line_height = textsize(\"Test\", font)[1] + 5\n",
        "        total_height = line_height * len(lines)\n",
        "        text_heights[index] = max(total_height, min_text_height)\n",
        "\n",
        "    comic_height = margin\n",
        "    for i in range(num_filas):\n",
        "        max_text_height = max(text_heights[i * num_columnas:(i + 1) * num_columnas])\n",
        "        comic_height += alto_img + max_text_height + margin\n",
        "\n",
        "    comic_width = num_columnas * ancho_img + (num_columnas + 1) * margin\n",
        "    comic = Image.new('RGB', (comic_width, comic_height), 'white')\n",
        "\n",
        "    current_top = margin\n",
        "    for fila in range(num_filas):\n",
        "        max_text_height = max(text_heights[fila * num_columnas:(fila + 1) * num_columnas])\n",
        "        for columna in range(num_columnas):\n",
        "            index = fila * num_columnas + columna\n",
        "            image = images[index]\n",
        "            left = columna * ancho_img + (columna + 1) * margin\n",
        "            comic.paste(image, (left, current_top))\n",
        "\n",
        "            draw = ImageDraw.Draw(comic)\n",
        "            text_top = current_top + alto_img + 5\n",
        "            draw.multiline_text((left, text_top), wrapped_text[index], font=font, fill=\"black\")\n",
        "\n",
        "        current_top += alto_img + max_text_height + margin\n",
        "\n",
        "    comic.save(save_path)\n",
        "    print(f\"The page was saved in {save_path}\")\n",
        "\n",
        "\n",
        "def wrap_bubble_text(text, width):\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = []\n",
        "    current_length = 0\n",
        "\n",
        "    for word in words:\n",
        "        if current_length + len(word) + len(current_line) > width:  # len(current_line) counts the spaces\n",
        "            if len(word) > width:\n",
        "                # Split long word with a dash\n",
        "                while len(word) > width:\n",
        "                    lines.append(word[:width-1] + \"-\")\n",
        "                    word = word[width-1:]\n",
        "                current_line = [word]\n",
        "                current_length = len(word)\n",
        "            else:\n",
        "                lines.append(' '.join(current_line))\n",
        "                current_line = [word]\n",
        "                current_length = len(word)\n",
        "        else:\n",
        "            current_line.append(word)\n",
        "            current_length += len(word)\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(' '.join(current_line))\n",
        "\n",
        "    return lines\n",
        "\n",
        "\n",
        "def add_comic_bubble(image_path, face_coords, text, font_path=\"Georgia.ttf\", bubble_path='bubble.png'):\n",
        "    # Load the main image\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Load the bubble image\n",
        "    bubble = Image.open(bubble_path)\n",
        "\n",
        "    # Determine face coordinates and size\n",
        "    x1 = int(face_coords[0])\n",
        "    y1 = int(face_coords[1])\n",
        "    x2 = int(face_coords[2])\n",
        "    y2 = int(face_coords[3])\n",
        "    face_center = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
        "\n",
        "    # Calculate where to place the bubble based on the face's vertical position\n",
        "    if face_center[1] > image.height / 2:\n",
        "        # If the face is in the upper half, place the bubble above\n",
        "        bubble_position = (int(face_center[0] - bubble.width // 2), y1 - bubble.height - 30)\n",
        "        bubble_orientation = bubble\n",
        "    else:\n",
        "        # If the face is in the lower half, place the bubble below\n",
        "        bubble_orientation = ImageOps.flip(bubble)\n",
        "        bubble_position = (int(face_center[0] - bubble.width // 2), y2 + 30)\n",
        "\n",
        "    # Paste the bubble onto the image\n",
        "    bubble_position = tuple(map(int, bubble_position))  # Convert bubble position to integer\n",
        "    image.paste(bubble_orientation, bubble_position, bubble_orientation)\n",
        "\n",
        "    # Draw the text inside the bubble\n",
        "    # Load a font\n",
        "    font = ImageFont.truetype(font_path, 24)\n",
        "\n",
        "    # Adjust text position based on orientation\n",
        "    if bubble_orientation is bubble:\n",
        "        initial_text_position = (bubble_position[0] + 50, bubble_position[1] + 230)  # Text position in normal bubble\n",
        "    else:\n",
        "        initial_text_position = (bubble_position[0] + 50, bubble_position[1] + bubble_orientation.height - 230)  # Adjust for flipped bubble\n",
        "\n",
        "    # Wrap text\n",
        "    wrapped_text = wrap_bubble_text(text, 22)\n",
        "\n",
        "    # Adjust text position and draw each line\n",
        "    y_offset = 0\n",
        "    for line in wrapped_text:\n",
        "        draw.text((initial_text_position[0], initial_text_position[1] + y_offset), line, fill='black', font=font)\n",
        "        y_offset += 30  # Adjust this based on font size and line spacing\n",
        "\n",
        "    # Return the modified image\n",
        "    return image\n",
        "\n",
        "\n",
        "def place_bubble(path, text, bubble_path, font_path):\n",
        "\n",
        "    img = read_image(path, None, augment=False, resize_len=[-1, -1])\n",
        "    init_img = get_PIL_image(img)\n",
        "    img = img.unsqueeze(0)\n",
        "    conf = 0.55\n",
        "    nms_thold = 0.2\n",
        "\n",
        "    cls_icf, boxes_icf = model_icf.predict_image(img, conf_thold=conf, nms_thold=nms_thold)\n",
        "\n",
        "    image = add_comic_bubble(path, boxes_icf[0], text, font_path=font_path, bubble_path=bubble_path)\n",
        "    image.save(path)\n",
        "\n",
        "\n",
        "\n",
        "def generate_image(scene, output_file, api_token, bubble_path, font_path):\n",
        "\n",
        "    prompt = scene['prompt']\n",
        "    is_quote = scene['is_quote']\n",
        "    text = scene['text']\n",
        "\n",
        "    print(\"GENERATING IMAGE...\")\n",
        "\n",
        "    API_URL = \"https://api-inference.huggingface.co/models/blink7630/graphic-novel-illustration\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
        "\n",
        "    payload = {'inputs': prompt}\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200 and response.headers['Content-Type'].startswith('image'):\n",
        "        image_bytes = response.content\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        image.save(output_file)\n",
        "        if is_quote:\n",
        "          print(\"PLACING BUBBLE...\")\n",
        "          place_bubble(output_file, text, bubble_path, font_path)\n",
        "        else:\n",
        "          print(\"NO BUBBLE\")\n",
        "        print(f\"Image saved in '{output_file}'.\")\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code)\n",
        "        print(\"Respuesta:\", response.text)\n",
        "\n",
        "# Image part\n",
        "\n",
        "def generate_comic_page(scenes, first_scene, book_id, api_token, bubble_path=\"bubble.png\", font_path=\"Georgia.ttf\"):\n",
        "\n",
        "    images_paths = []\n",
        "    dialogues = []\n",
        "\n",
        "    # Create the output dir if it doesn't exist\n",
        "    os.makedirs(f\"output_dir/{book_id}/img/scenes\", exist_ok=True)\n",
        "    os.makedirs(f\"output_dir/{book_id}/img/pages\", exist_ok=True)\n",
        "\n",
        "    for i, scene in enumerate(scenes):\n",
        "        image_path = f\"output_dir/{book_id}/img/scenes/scene{i+first_scene}.png\"\n",
        "        generate_image(scene, image_path, api_token, bubble_path, font_path)\n",
        "        images_paths.append(image_path)\n",
        "        dialogues.append(scene['text'])\n",
        "        print(f\"Scene {i+first_scene} generated\")\n",
        "\n",
        "    output_file = f\"output_dir/{book_id}/img/pages/page{int(first_scene/6)}.png\"\n",
        "\n",
        "    create_comic_grid(images_paths, dialogues, font_path, output_file, grid_size=(3,2), margin=20, min_text_height=80)\n",
        "\n",
        "    print(\"Page generated\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "def get_binary_file_downloader_html(bin_file, file_label='File'):\n",
        "    with open(bin_file, 'rb') as f:\n",
        "        data = f.read()\n",
        "    bin_str = base64.b64encode(data).decode()\n",
        "    href = f'<a href=\"data:application/octet-stream;base64,{bin_str}\" download=\"{os.path.basename(bin_file)}\">Download {file_label}</a>'\n",
        "    return href"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMJTIRJlNKe8"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8I9Ur_9Pjb6"
      },
      "source": [
        "Mount drive, if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyW3Xvp_Prze"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGkdfzHdvz3r"
      },
      "source": [
        "Load weights for bubble model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfARYCa8v6vQ"
      },
      "outputs": [],
      "source": [
        "# CHANGE THIS\n",
        "path_to_weights = \"/content/drive/MyDrive/No_Estructurado/Book2Comic/model/final_icf_r50.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGDTIaU9v7QB"
      },
      "outputs": [],
      "source": [
        "model_icf = RetinaFace(backbone=\"resnet50\")\n",
        "model_icf.load_state_dict(torch.load(path_to_weights))\n",
        "model_icf = model_icf.to(device)\n",
        "model_icf.eval()\n",
        "print(\"[INFO] Model is loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l90MtSzpy_M9"
      },
      "source": [
        "Specify bubble image and font paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiHLGKeDzDKl"
      },
      "outputs": [],
      "source": [
        "bubble_path = \"/content/drive/MyDrive/No_Estructurado/Book2Comic/static/bubble.png\"\n",
        "font_path = \"/content/drive/MyDrive/No_Estructurado/Book2Comic/static/Georgia.ttf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMTwziviP5LS"
      },
      "source": [
        "Load the book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XMuayHJP7bF"
      },
      "outputs": [],
      "source": [
        "# CHANGE THIS\n",
        "path_to_book = \"/content/drive/MyDrive/No_Estructurado/Book2Comic/books/the_man_with_the_twisted_lip.txt\"\n",
        "book_name = \"The man with the twisted lip\"\n",
        "book_author = \"Arthur Conan Doyle\"\n",
        "\n",
        "book_files_name =book_name.lower().strip().replace(\" \", \"_\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdBRWbMUQRtq"
      },
      "source": [
        "Split in paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPK8R7XiQQdr"
      },
      "outputs": [],
      "source": [
        "paragraphs = split_into_paragraphs(path_to_book)\n",
        "n_paragraphs = len(paragraphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY2_32a6Q84L"
      },
      "source": [
        "Extract characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541,
          "referenced_widgets": [
            "b59efa7a5f274703b1f8a42e3a5c33bf",
            "77fa91cb5c0c4f9482ea7a0806e85c96",
            "f2f8e4f5c2a7434b9d2570de18a07553",
            "5b204e07cfe74ff69e1090d1e98014c3",
            "c14eefe9815e418da944b79ea947cce2",
            "95f7e623b48142e19c245aca17cb80f7",
            "ef679dd0b05b440c8ad02bb528ac7ed7",
            "b1a8300046f64a3fb63d9749f6b3e014",
            "9ff787165b5e4cea9fb6d27135e647c5",
            "d475addada01433bb05211adfb09ab7a",
            "2cd397e7ab2e41f18a2fc40fb30715a4",
            "71137713c9834b8db454e82d49a23394",
            "6ed6ad6046ef4579b159556d871b199c",
            "54147ebfab74409c997ef314993aed9f",
            "19517e23670c4dc48a695d6012ba9564",
            "c06dbfd4735247ef924f9c40be837c17",
            "aef27d0cf4a3402d8a1f0a71fdd0d2f2",
            "1dd12085e0d54e0086ca71082323057e",
            "25aed0712d864dc8bb7c7c155aa3ebd2",
            "82e525a583984a908098d2f018085591",
            "4bcc9466ff7142ab9d2b4502d882cc4f",
            "ac9ab05035fb48afb29857c92945f621",
            "5e6f598ca64f4f9d87946e150f8a0eb6",
            "367e28b3b4ea491485715dfe2b91e991",
            "2a12c549e12f400a8b27644ddab74229",
            "f145b82e84964ac2b37926fab46cc707",
            "c5415aad15b44d7091b6e69a2d1643f1",
            "97681f4b40e44b61b2aa088b5cf913b8",
            "3cf65584c2a041268a3669a34dda419d",
            "442afb6289a6454799bd6bdf302e8e88",
            "1c977333c506449ebaa58f5809676293",
            "b53f4cd5f9dc49898766271c8ad680df",
            "605dc6131d534e90a43dc2930a4ae0ee",
            "f1ad97c927734d0fb30ca7113ee3b343",
            "ba931aa751e446fcb37285958e21de3e",
            "8dc7e99984bc4f45b28404ffa2ff7f46",
            "19dd7bee95b6472bb201011d74084cb7",
            "7cbd295fdceb4211b14e6af28c9aaf45",
            "56035cb105284694809e6a4e5c7297aa",
            "87dbe5b5c4654e579980865685efaf7e",
            "41c80f7b67b945fba88de00074b175ae",
            "55cfaa50f39140f482e5fc9bd98fa7b7",
            "35c09f4cd25e4b3db7c30d506a544f71",
            "0eb90e069313428ba18432d7a558bd5d",
            "8c912d18e4ed42cfa406113e7eb520e9",
            "9fdd76cc30e04122adb5d3c21b71b58f",
            "25ceb96829d44e42be145498cef6bf11",
            "a0a718ee6f044b83b751cd6e2035957f",
            "2ced38391a17467c81094d9fa7b6f5b6",
            "da13619c28f140bf943ca7c28209f671",
            "42433f97df334ece87cf0b97fcf22602",
            "3b4263e6fc6e43cdb4db1feda0e7b89b",
            "68d3c446a98d4f0d92a14ced557a2fcf",
            "e1533b000fe842a8a145ae67a27991a5",
            "cb12796443544141bc6dd3a37f34d600",
            "c72493813e364667b5c8d0fbc191c962",
            "038d2aaa4ffb4b96aecf26e5ce1d72eb",
            "f1e8c806a93844bab23e587a4f031b53",
            "bc8aef4cd32d43d2bfb7e0134f0b9316",
            "fb92a6361afe464d956b46c2ceaf062e",
            "0c89eb096e284a1f8610ab670761019b",
            "33545e4a6fa74f67ae66cfe4909e7a85",
            "8b41bea51b6d4288b90c269b8c44f662",
            "5a080de39ee5425286357c11c9319f36",
            "bb6c650b0a3f415184dc2a2dbbc38797",
            "7af3a2a8492448709b14937808f8bab0"
          ]
        },
        "id": "l3bTqMjsQ--e",
        "outputId": "b4f1f2e3-86b0-4df3-b1cf-5966821ade28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'big'}\n",
            "downloading entities_google_bert_uncased_L-6_H-768_A-12-v1.0.model\n",
            "downloading coref_google_bert_uncased_L-12_H-768_A-12-v1.0.model\n",
            "downloading speaker_google_bert_uncased_L-12_H-768_A-12-v1.0.1.model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b59efa7a5f274703b1f8a42e3a5c33bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71137713c9834b8db454e82d49a23394",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e6f598ca64f4f9d87946e150f8a0eb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/270M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1ad97c927734d0fb30ca7113ee3b343",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c912d18e4ed42cfa406113e7eb520e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c72493813e364667b5c8d0fbc191c962",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- startup: 47.857 seconds ---\n",
            "--- spacy: 3.480 seconds ---\n",
            "--- entities: 17.561 seconds ---\n",
            "--- quotes: 0.133 seconds ---\n",
            "--- attribution: 13.076 seconds ---\n",
            "--- name coref: 0.015 seconds ---\n",
            "--- coref: 11.302 seconds ---\n",
            "--- TOTAL (excl. startup): 45.624 seconds ---, 11218 words\n"
          ]
        }
      ],
      "source": [
        "character_list = extract_characters(book_files_name, path_to_book, book_files_name)\n",
        "character_names = [c['names'][0] for c in character_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK-_4R_8R40U",
        "outputId": "ea83a683-4ecf-4539-89d7-b80bda8d6195"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'names': ['Holmes'], 'gender': 'he/him/his', 'coref': 31},\n",
              " {'names': ['[NARRATOR]'], 'gender': 'unknown', 'coref': 0},\n",
              " {'names': ['Mr. Neville St. Clair'], 'gender': 'he/him/his', 'coref': 32},\n",
              " {'names': ['Hugh Boone'], 'gender': 'he/him/his', 'coref': 38},\n",
              " {'names': ['Mrs. St. Clair'], 'gender': 'she/her', 'coref': 35},\n",
              " {'names': ['Isa Whitney'], 'gender': 'he/him/his', 'coref': 24},\n",
              " {'names': ['Watson'], 'gender': 'he/him/his', 'coref': 30},\n",
              " {'names': ['the Lascar'], 'gender': 'he/him/his', 'coref': 305},\n",
              " {'names': ['Inspector Bradstreet'], 'gender': 'he/him/his', 'coref': 41},\n",
              " {'names': ['Kate'], 'gender': 'she/her', 'coref': 28},\n",
              " {'names': ['Lee'], 'gender': 'he/him/his', 'coref': 5},\n",
              " {'names': ['John'], 'gender': 'he/him/his', 'coref': 33},\n",
              " {'names': ['God'], 'gender': 'he/him/his', 'coref': 40}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "character_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu3skPEHR6R8"
      },
      "source": [
        "Add or remove characters from the list, if you want. Do not include coref as a key: it will be calculated automatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RY1KPnKR-WH"
      },
      "outputs": [],
      "source": [
        "# Remove God (not a character, but mentioned as a expression) and add the narrator's wife (not detected but present in the story)\n",
        "\n",
        "character_list = character_list[:-1]\n",
        "character_list.append({'names': ['my wife'], 'gender': 'she/her'})\n",
        "\n",
        "# Need to get the coref again for the new characters\n",
        "character_list = get_character_ids(f\"booknlp_files/{book_files_name}/{book_files_name}.entities\", character_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_L_rl4fSyzL",
        "outputId": "af08e4ed-57fe-41c8-87ae-aed2b2e19b9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'names': ['Holmes'], 'gender': 'he/him/his', 'coref': 31},\n",
              " {'names': ['[NARRATOR]'], 'gender': 'unknown', 'coref': 0},\n",
              " {'names': ['Mr. Neville St. Clair'], 'gender': 'he/him/his', 'coref': 32},\n",
              " {'names': ['Hugh Boone'], 'gender': 'he/him/his', 'coref': 38},\n",
              " {'names': ['Mrs. St. Clair'], 'gender': 'she/her', 'coref': 35},\n",
              " {'names': ['Isa Whitney'], 'gender': 'he/him/his', 'coref': 24},\n",
              " {'names': ['Watson'], 'gender': 'he/him/his', 'coref': 30},\n",
              " {'names': ['the Lascar'], 'gender': 'he/him/his', 'coref': 305},\n",
              " {'names': ['Inspector Bradstreet'], 'gender': 'he/him/his', 'coref': 41},\n",
              " {'names': ['Kate'], 'gender': 'she/her', 'coref': 28},\n",
              " {'names': ['Lee'], 'gender': 'he/him/his', 'coref': 5},\n",
              " {'names': ['John'], 'gender': 'he/him/his', 'coref': 33},\n",
              " {'names': ['my wife'], 'gender': 'she/her', 'coref': 51}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "character_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y41Bhg47S1xi"
      },
      "source": [
        "Get a structure with the quotes in the book and the characters that said them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nivKea1uS7PT"
      },
      "outputs": [],
      "source": [
        "quotes = construct_quote_to_character(book_files_name, book_files_name, character_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqHHetFRTJvh"
      },
      "source": [
        "Extract descriptions. IT IS NECESSARY TO PROVIDE A HUGGING FACE API TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vahOpdu4TWS9",
        "outputId": "44e6778e-7b86-490f-8903-0e1c87e6a656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "# CHANGE THIS\n",
        "import getpass\n",
        "api_token = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "kE4Mgd4KTVrA",
        "outputId": "735a8ee2-6419-4615-c7f7-bdb1d2314743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating attributes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-fab99ba57f8b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdescription_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_descriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_book\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-5cf75c429635>\u001b[0m in \u001b[0;36mextract_descriptions\u001b[0;34m(input_file, named_characters, hb_api_key, use_local_model)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating attributes...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0mcharacters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamed_characters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating descriptions...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-5cf75c429635>\u001b[0m in \u001b[0;36mgenerate_attributes\u001b[0;34m(text, character_list)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0;31m# Example: Extract adjectives describing the character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ADJ\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                             \u001b[0mdescriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mtokvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \"\"\"\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUMPY_OPS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray1i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mXf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mYf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dXf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdYs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mListXd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mListXd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/residual.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0md_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/maxout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape2f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape1f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape3f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "description_dict = extract_descriptions(path_to_book, character_list, api_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40V-4SDTTwIk",
        "outputId": "07580837-685e-40b6-c4df-55788fd1aa99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Holmes': 'A tall man with a quiet, coarse face, curious golden eyes, and a singular, pale complexion. His attire is plain and much too large for his small stature a cold, blue coat with a last button undone, and indentured brown trousers. He wears an indistinct, definite hat on his head. The unanswered air about him suggests a great, unsolved fear in that singular mind, and a certain debt to',\n",
              " '[NARRATOR]': 'A slender, pale mal with short, black hair and emerald green eyes, wearing a black suit and a red tie.',\n",
              " 'Mr. Neville St. Clair': 'A distinguished gentleman with thinning, silver hair and piercing, black eyes, dressed in a crisp, navy blue threepiece suit and a red silk cravat.',\n",
              " 'Hugh Boone': 'A massive, hideous figure, with an absolutely imposing presence and familiar aura, dressed in tattered but present rags.',\n",
              " 'Mrs. St. Clair': 'No need for a whole paragraph! A voluptuous woman with striking blonde hair, piercing emerald green eyes, and an elegant, refined appearance. Wearing a chic, maroon wrap dress that accentuates her curves, and a pair of black, highheeled pumps. A pearl necklace and diamond earrings adorn her ears, adding to her sophisticated look.',\n",
              " 'Isa Whitney': 'Isa Whitney, a disheveled, thin, young man with twitchy, restless hands, appearing late and unshaven, his eyes bloodshot and wild, a lifelong addict, was wearing a threadbare medical coat over torn jeans and a faded Tshirt.',\n",
              " 'Watson': 'A tall, goldenhaired man with remarkable height and exceptional, incoherent speech, wearing a dark suit and a grand, absolute medical diploma around his neck. Little hairs cover his pale, yellow skin, and his awake, golden eyes scan over every detail in an attempt to gather every little piece of information.',\n",
              " 'the Lascar': 'He is a darkskinned man with a thick beard, piercing black eyes, strong jawline and muscular build, wearing a multicolored turban and loose, flowing white robes, adorned with intricate gold jewelry.',\n",
              " 'Inspector Bradstreet': 'A proper, unobserved inspector with a difficult expression and a sure demeanor, donning a welltailored suit and a crisp, white shirt.',\n",
              " 'Kate': 'A petite woman with disheveled, dark hair and wide, desperate eyes. she wears tattered clothes and no shoes. Her thin frame is barely covered by a dirty, torn blouse and wornout denim skirt.',\n",
              " 'Lee': 'A definite, muscular man in his late thirties with shortcropped black hair, piercing blue eyes and a jawline as sharp as a knife. Wearing a tailored black suit that elegantly accentuates his extra broad shoulders, paired with a crisp white shirt and a vivid red tie. His clothing exudes confidence and power, matching his firm and precise demeanor.',\n",
              " 'John': 'A rugged man in his late 30s with lean muscles, broad shoulders, and a scruffy beard. Wearing a flannel shirt, khaki pants, and hiking boots.',\n",
              " 'my wife': 'My wife is a petite woman with long, curly, chestnutbrown hair cascading down her shoulders and big, hazel eyes that crinkle with warmth when she smiles. She wears a vibrant floral sundress that matches her red lips and the sunlight adorning her delicate features.'}"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "description_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZOmveAaQ_bN"
      },
      "source": [
        "Check the descriptions and change them in necessary... Mistral sometimes can be a bit too specific or too simple, or even include more text than you are asking for... It is a powerful tool, but still needs some supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKX4GXdHUGpO"
      },
      "outputs": [],
      "source": [
        "# CHANGE THIS\n",
        "\n",
        "# The narrator is not a woman\n",
        "description_dict['[NARRATOR]'] = 'A slender, pale mal with short, black hair and emerald green eyes, wearing a black suit and a red tie.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le87goAaU41J"
      },
      "source": [
        "Generate scenes: textual descriptions and text that will go inside. Let's do it for the first 6 scenes (you can change this later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uen_v15_VBoy",
        "outputId": "c0d05c0a-e98e-4cbc-eab0-0f2b1ad4cad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATING SCENE FOR PARAGRAPH:\n",
            "Isa Whitney, brother of the late Elias Whitney, D.D., Principal of the Theological College of St. George's, was much addicted to opium. The habit grew upon him, as I understand, from some foolish freak when he was at college; for having read De Quincey's description of his dreams and sensations, he had drenched his tobacco with laudanum in an attempt to produce the same effects. He found, as so many more have done, that the practice is easier to attain than to get rid of, and for many years he continued to be a slave to the drug, an object of mingled horror and pity to his friends and relatives. I can see him now, with yellow, pasty face, drooping lids, and pin-point pupils, all huddled in a chair, the wreck and ruin of a noble man.\n",
            "CHARACTERS IN SCENE:\n",
            "['Isa Whitney', '[NARRATOR]']\n",
            "GENERATING SCENE FOR PARAGRAPH:\n",
            "One night--it was in June, '89--there came a ring to my bell, about the hour when a man gives his first yawn and glances at the clock. I sat up in my chair, and my wife laid her needle-work down in her lap and made a little face of disappointment.\n",
            "CHARACTERS IN SCENE:\n",
            "['my wife', '[NARRATOR]']\n",
            "GENERATING SCENE FOR PARAGRAPH:\n",
            "\"A patient!\" said she. \"You'll have to go out.\"\n",
            "CHARACTERS IN SCENE:\n",
            "['my wife', '[NARRATOR]']\n",
            "GENERATING SCENE FOR PARAGRAPH:\n",
            "I groaned, for I was newly come back from a weary day.\n",
            "CHARACTERS IN SCENE:\n",
            "['[NARRATOR]']\n",
            "GENERATING SCENE FOR PARAGRAPH:\n",
            "We heard the door open, a few hurried words, and then quick steps upon the linoleum. Our own door flew open, and a lady, clad in some dark-coloured stuff, with a black veil, entered the room.\n",
            "CHARACTERS IN SCENE:\n",
            "['[NARRATOR]']\n",
            "GENERATING SCENE FOR PARAGRAPH:\n",
            "\"You will excuse my calling so late,\" she began, and then, suddenly losing her self-control, she ran forward, threw her arms about my wife's neck, and sobbed upon her shoulder. \"Oh, I'm in such trouble!\" she cried; \"I do so want a little help.\"\n",
            "CHARACTERS IN SCENE:\n",
            "['my wife', '[NARRATOR]']\n"
          ]
        }
      ],
      "source": [
        "scenes = generate_textual_scenes(paragraphs[:6], character_list, description_dict, quotes, api_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTocqmJGcXnP",
        "outputId": "83b90dcd-fab1-4652-847a-cf20a2590f2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'prompt': 'A disheveled, thin young man in a threadbare medical coat, wearing torn jeans and a faded Tshirt, slumps in an armchair with twitchy restless hands. His face is yellow and pasty, with drooping lids and pinpoint pupils. The room is dimly lit, with tall windows, showing the falling rain, speckling the grey pavement outside. A small table beside the chair holds a vial of',\n",
              "  'text': 'Isa Whitney, once a noble scholar, succumbs to the destructive power of opium.',\n",
              "  'is_quote': False},\n",
              " {'prompt': 'A petite woman with long, chestnutbrown hair and big hazel eyes, wearing a vibrant floral sundress, seated on a chair with a weary expression. Beside her sits a slender, pale man with short, black hair and emerald green eyes, wearing a black suit and a red tie, looking at her with a solemn expression. The scene takes place inside a spacious, dimly lit room with tall windows revealing a rainy',\n",
              "  'text': 'A quiet evening interrupted.',\n",
              "  'is_quote': False},\n",
              " {'prompt': 'A petite woman with long, chestnutbrown hair, wearing a vibrant floral sundress, speaks to a slender, pale man with short, black hair while standing near a tall window with raindrops flowing down it. The man wears a black suit and a red tie. Both characters look worried and serious.',\n",
              "  'text': 'Viscountess rushing past with a tray of tea. \"Sorry for the inconvenience, my lord,\" she called behind her.',\n",
              "  'is_quote': True},\n",
              " {'prompt': 'A lone figure in a black suit and red tie, sitting in front of a rainsplattered window, putting his hand on his groaning forehead as he sighs wearily.',\n",
              "  'text': 'Exhausted warrior returns home. (No need for \"I was\") or Home after a long day\\'s fight.',\n",
              "  'is_quote': False},\n",
              " {'prompt': 'A veiled lady, in dark clothing, enters a room with a weary man in a black suit and red tie.',\n",
              "  'text': 'A gust of wind brings in the veiled lady.',\n",
              "  'is_quote': False},\n",
              " {'prompt': \"A petite woman in a vibrant floral sundress with curly chestnutbrown hair and warm hazel eyes, cradling another woman in a black suit and red tie, both standing in a room with sunlight streaming in, the veiled woman weeping on the other's shoulder.\",\n",
              "  'text': '\"A desperate cry for aid,\" OR \"Desperation etched on her face.\" OR \"Seeking solace in a stranger\\'s arms.\"',\n",
              "  'is_quote': True}]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSAjIAlqsufm"
      },
      "source": [
        "As we can see, the prompts are fine, but Mistral sometimes generates several texts, as if it was chatting with us, although we explicitly tell it to return ONLY one text.\n",
        "\n",
        "This problem could be solved with prompt engineering or using a better LLM (we tried GPT4 and oh god was it noticeable). Nevertheless, since we want to do this project open source and possible to be run locally, we must stick to Mistral.\n",
        "\n",
        "And so, let's change the text a bit (again, human supervision is required)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fRPvmsbtZXQ"
      },
      "outputs": [],
      "source": [
        "# CHANGE THIS\n",
        "\n",
        "scenes[2]['text'] = \"A patient! You'll have to go out.\"\n",
        "scenes[5]['text'] = \"You will excuse my calling so late. Oh, I'm in such trouble! I do so want a little help.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysjRhmcHci8q"
      },
      "source": [
        "Generate images from the textual scenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "IFgTWo51ciCT",
        "outputId": "3def8ae9-bc9a-4f63-fd39-763986fa457b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATING IMAGE...\n",
            "NO BUBBLE\n",
            "Image saved in 'output_dir/the_man_with_the_twisted_lip/img/scenes/scene0.png'.\n",
            "Scene 0 generated\n",
            "GENERATING IMAGE...\n",
            "NO BUBBLE\n",
            "Image saved in 'output_dir/the_man_with_the_twisted_lip/img/scenes/scene1.png'.\n",
            "Scene 1 generated\n",
            "GENERATING IMAGE...\n",
            "PLACING BUBBLE...\n",
            "Image saved in 'output_dir/the_man_with_the_twisted_lip/img/scenes/scene2.png'.\n",
            "Scene 2 generated\n",
            "GENERATING IMAGE...\n",
            "NO BUBBLE\n",
            "Image saved in 'output_dir/the_man_with_the_twisted_lip/img/scenes/scene3.png'.\n",
            "Scene 3 generated\n",
            "GENERATING IMAGE...\n",
            "NO BUBBLE\n",
            "Image saved in 'output_dir/the_man_with_the_twisted_lip/img/scenes/scene4.png'.\n",
            "Scene 4 generated\n",
            "GENERATING IMAGE...\n",
            "PLACING BUBBLE...\n",
            "Image saved in 'output_dir/the_man_with_the_twisted_lip/img/scenes/scene5.png'.\n",
            "Scene 5 generated\n",
            "The page was saved in output_dir/the_man_with_the_twisted_lip/img/pages/page0.png\n",
            "Page generated\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'output_dir/the_man_with_the_twisted_lip/img/pages/page0.png'"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_comic_page(scenes, 0, book_files_name, api_token, bubble_path, font_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "P1-TGJfeEeqY",
        "V75a6_9EEh52",
        "x5agDg1IE2tA",
        "HXtidZ4_Ly72",
        "YSWspSkZwMVi"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "038d2aaa4ffb4b96aecf26e5ce1d72eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c89eb096e284a1f8610ab670761019b",
            "placeholder": "​",
            "style": "IPY_MODEL_33545e4a6fa74f67ae66cfe4909e7a85",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0c89eb096e284a1f8610ab670761019b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb90e069313428ba18432d7a558bd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19517e23670c4dc48a695d6012ba9564": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bcc9466ff7142ab9d2b4502d882cc4f",
            "placeholder": "​",
            "style": "IPY_MODEL_ac9ab05035fb48afb29857c92945f621",
            "value": " 384/384 [00:00&lt;00:00, 23.8kB/s]"
          }
        },
        "19dd7bee95b6472bb201011d74084cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c09f4cd25e4b3db7c30d506a544f71",
            "placeholder": "​",
            "style": "IPY_MODEL_0eb90e069313428ba18432d7a558bd5d",
            "value": " 232k/232k [00:00&lt;00:00, 11.8MB/s]"
          }
        },
        "1c977333c506449ebaa58f5809676293": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dd12085e0d54e0086ca71082323057e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25aed0712d864dc8bb7c7c155aa3ebd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ceb96829d44e42be145498cef6bf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4263e6fc6e43cdb4db1feda0e7b89b",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68d3c446a98d4f0d92a14ced557a2fcf",
            "value": 385
          }
        },
        "2a12c549e12f400a8b27644ddab74229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_442afb6289a6454799bd6bdf302e8e88",
            "max": 270341459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c977333c506449ebaa58f5809676293",
            "value": 270341459
          }
        },
        "2cd397e7ab2e41f18a2fc40fb30715a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ced38391a17467c81094d9fa7b6f5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33545e4a6fa74f67ae66cfe4909e7a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35c09f4cd25e4b3db7c30d506a544f71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "367e28b3b4ea491485715dfe2b91e991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97681f4b40e44b61b2aa088b5cf913b8",
            "placeholder": "​",
            "style": "IPY_MODEL_3cf65584c2a041268a3669a34dda419d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "3b4263e6fc6e43cdb4db1feda0e7b89b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf65584c2a041268a3669a34dda419d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41c80f7b67b945fba88de00074b175ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42433f97df334ece87cf0b97fcf22602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "442afb6289a6454799bd6bdf302e8e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bcc9466ff7142ab9d2b4502d882cc4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54147ebfab74409c997ef314993aed9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25aed0712d864dc8bb7c7c155aa3ebd2",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82e525a583984a908098d2f018085591",
            "value": 384
          }
        },
        "55cfaa50f39140f482e5fc9bd98fa7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56035cb105284694809e6a4e5c7297aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a080de39ee5425286357c11c9319f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b204e07cfe74ff69e1090d1e98014c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d475addada01433bb05211adfb09ab7a",
            "placeholder": "​",
            "style": "IPY_MODEL_2cd397e7ab2e41f18a2fc40fb30715a4",
            "value": " 232k/232k [00:00&lt;00:00, 3.78MB/s]"
          }
        },
        "5e6f598ca64f4f9d87946e150f8a0eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_367e28b3b4ea491485715dfe2b91e991",
              "IPY_MODEL_2a12c549e12f400a8b27644ddab74229",
              "IPY_MODEL_f145b82e84964ac2b37926fab46cc707"
            ],
            "layout": "IPY_MODEL_c5415aad15b44d7091b6e69a2d1643f1"
          }
        },
        "605dc6131d534e90a43dc2930a4ae0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68d3c446a98d4f0d92a14ced557a2fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ed6ad6046ef4579b159556d871b199c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aef27d0cf4a3402d8a1f0a71fdd0d2f2",
            "placeholder": "​",
            "style": "IPY_MODEL_1dd12085e0d54e0086ca71082323057e",
            "value": "config.json: 100%"
          }
        },
        "71137713c9834b8db454e82d49a23394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ed6ad6046ef4579b159556d871b199c",
              "IPY_MODEL_54147ebfab74409c997ef314993aed9f",
              "IPY_MODEL_19517e23670c4dc48a695d6012ba9564"
            ],
            "layout": "IPY_MODEL_c06dbfd4735247ef924f9c40be837c17"
          }
        },
        "77fa91cb5c0c4f9482ea7a0806e85c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f7e623b48142e19c245aca17cb80f7",
            "placeholder": "​",
            "style": "IPY_MODEL_ef679dd0b05b440c8ad02bb528ac7ed7",
            "value": "vocab.txt: 100%"
          }
        },
        "7af3a2a8492448709b14937808f8bab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cbd295fdceb4211b14e6af28c9aaf45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e525a583984a908098d2f018085591": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87dbe5b5c4654e579980865685efaf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b41bea51b6d4288b90c269b8c44f662": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c912d18e4ed42cfa406113e7eb520e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fdd76cc30e04122adb5d3c21b71b58f",
              "IPY_MODEL_25ceb96829d44e42be145498cef6bf11",
              "IPY_MODEL_a0a718ee6f044b83b751cd6e2035957f"
            ],
            "layout": "IPY_MODEL_2ced38391a17467c81094d9fa7b6f5b6"
          }
        },
        "8dc7e99984bc4f45b28404ffa2ff7f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c80f7b67b945fba88de00074b175ae",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55cfaa50f39140f482e5fc9bd98fa7b7",
            "value": 231508
          }
        },
        "95f7e623b48142e19c245aca17cb80f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97681f4b40e44b61b2aa088b5cf913b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fdd76cc30e04122adb5d3c21b71b58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da13619c28f140bf943ca7c28209f671",
            "placeholder": "​",
            "style": "IPY_MODEL_42433f97df334ece87cf0b97fcf22602",
            "value": "config.json: 100%"
          }
        },
        "9ff787165b5e4cea9fb6d27135e647c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0a718ee6f044b83b751cd6e2035957f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1533b000fe842a8a145ae67a27991a5",
            "placeholder": "​",
            "style": "IPY_MODEL_cb12796443544141bc6dd3a37f34d600",
            "value": " 385/385 [00:00&lt;00:00, 27.4kB/s]"
          }
        },
        "ac9ab05035fb48afb29857c92945f621": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aef27d0cf4a3402d8a1f0a71fdd0d2f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1a8300046f64a3fb63d9749f6b3e014": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53f4cd5f9dc49898766271c8ad680df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59efa7a5f274703b1f8a42e3a5c33bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77fa91cb5c0c4f9482ea7a0806e85c96",
              "IPY_MODEL_f2f8e4f5c2a7434b9d2570de18a07553",
              "IPY_MODEL_5b204e07cfe74ff69e1090d1e98014c3"
            ],
            "layout": "IPY_MODEL_c14eefe9815e418da944b79ea947cce2"
          }
        },
        "ba931aa751e446fcb37285958e21de3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56035cb105284694809e6a4e5c7297aa",
            "placeholder": "​",
            "style": "IPY_MODEL_87dbe5b5c4654e579980865685efaf7e",
            "value": "vocab.txt: 100%"
          }
        },
        "bb6c650b0a3f415184dc2a2dbbc38797": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8aef4cd32d43d2bfb7e0134f0b9316": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb6c650b0a3f415184dc2a2dbbc38797",
            "placeholder": "​",
            "style": "IPY_MODEL_7af3a2a8492448709b14937808f8bab0",
            "value": " 440M/440M [00:13&lt;00:00, 25.5MB/s]"
          }
        },
        "c06dbfd4735247ef924f9c40be837c17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14eefe9815e418da944b79ea947cce2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5415aad15b44d7091b6e69a2d1643f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72493813e364667b5c8d0fbc191c962": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_038d2aaa4ffb4b96aecf26e5ce1d72eb",
              "IPY_MODEL_f1e8c806a93844bab23e587a4f031b53",
              "IPY_MODEL_bc8aef4cd32d43d2bfb7e0134f0b9316"
            ],
            "layout": "IPY_MODEL_fb92a6361afe464d956b46c2ceaf062e"
          }
        },
        "cb12796443544141bc6dd3a37f34d600": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d475addada01433bb05211adfb09ab7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da13619c28f140bf943ca7c28209f671": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1533b000fe842a8a145ae67a27991a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef679dd0b05b440c8ad02bb528ac7ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f145b82e84964ac2b37926fab46cc707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53f4cd5f9dc49898766271c8ad680df",
            "placeholder": "​",
            "style": "IPY_MODEL_605dc6131d534e90a43dc2930a4ae0ee",
            "value": " 270M/270M [00:07&lt;00:00, 36.3MB/s]"
          }
        },
        "f1ad97c927734d0fb30ca7113ee3b343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba931aa751e446fcb37285958e21de3e",
              "IPY_MODEL_8dc7e99984bc4f45b28404ffa2ff7f46",
              "IPY_MODEL_19dd7bee95b6472bb201011d74084cb7"
            ],
            "layout": "IPY_MODEL_7cbd295fdceb4211b14e6af28c9aaf45"
          }
        },
        "f1e8c806a93844bab23e587a4f031b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b41bea51b6d4288b90c269b8c44f662",
            "max": 440472395,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a080de39ee5425286357c11c9319f36",
            "value": 440472395
          }
        },
        "f2f8e4f5c2a7434b9d2570de18a07553": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1a8300046f64a3fb63d9749f6b3e014",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ff787165b5e4cea9fb6d27135e647c5",
            "value": 231508
          }
        },
        "fb92a6361afe464d956b46c2ceaf062e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
